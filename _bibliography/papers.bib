---
---


@article{doi:10.34133/2022/9795275,
  abbr={Plant Phenomics},
  author = {Rawat, Shivangana and Chandra, Akshay L and Desai, Sai Vikas and Balasubramanian, Vineeth N and Ninomiya, Seishi and Guo, Wei},
  title = {How Useful Is Image-Based Active Learning for Plant Organ Segmentation?},
  journal = {Plant Phenomics},
  volume = {2022},
  year = {2022},
  month = {February},
  doi = {10.34133/2022/9795275},
  html = {https://spj.science.org/doi/abs/10.34133/2022/9795275},
  pdf = {https://spj.science.org/doi/pdf/10.34133/2022/9795275},
  code = {https://github.com/ShivanganaRawat/ALPO_Segmentation},
  abstract = {Training deep learning models typically requires a huge amount of labeled data which is expensive to acquire, especially in dense prediction tasks such as semantic segmentation. Moreover, plant phenotyping datasets pose additional challenges of heavy occlusion and varied lighting conditions which makes annotations more time-consuming to obtain. Active learning helps in reducing the annotation cost by selecting samples for labeling which are most informative to the model, thus improving model performance with fewer annotations. Active learning for semantic segmentation has been well studied on datasets such as PASCAL VOC and Cityscapes. However, its effectiveness on plant datasets has not received much importance. To bridge this gap, we empirically study and benchmark the effectiveness of four uncertainty-based active learning strategies on three natural plant organ segmentation datasets. We also study their behaviour in response to variations in training configurations in terms of augmentations used, the scale of training images, active learning batch sizes, and train-validation set splits.}
}

@article{pmlr-v148-chandra21a,
  abbr={PMLR/NeurIPS W},
  title = {On Initial Pools for Deep Active Learning},
  author = {Chandra*, Akshay L and Desai*, Sai Vikas and Devaguptapu*, Chaitanya and Balasubramanian, Vineeth N.},
  journal = {NeurIPS 2020 Workshop on Pre-registration in Machine Learning},
  pages = {14-32},
  year = {2021},
  editor = {Bertinetto, Luca and Henriques, João F. and Albanie, Samuel and Paganini, Michela and Varol, Gül},
  volume = {148},
  series = {Proceedings of Machine Learning Research},
  month = {December},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v148/chandra21a/chandra21a.pdf},
  url = {https://proceedings.mlr.press/v148/chandra21a.html},
  code = {https://github.com/acl21/init-pools-dal},
  abstract = 	 {Active Learning (AL) techniques aim to minimize the training data required to train a model for a given task. Pool-based AL techniques start with a small initial labeled pool and then iteratively pick batches of the most informative samples for labeling. Generally, the initial pool is sampled randomly and labeled to seed the AL iterations. While recent studies have focused on evaluating the robustness of various query functions in AL, little to no attention has been given to the design of the initial labeled pool for deep active learning. Given the recent successes of learning representations in self-supervised/unsupervised ways, we study if an intelligently sampled initial labeled pool can improve deep AL performance. We investigate the effect of intelligently sampled initial labeled pools, including the use of self-supervised and unsupervised strategies, on deep AL methods. The setup, hypotheses, methodology, and implementation details were evaluated by peer review before experiments were conducted. Experimental results could not conclusively prove that intelligently sampled initial pools are better for AL than random initial pools in the long run, although a Variational Autoencoder-based initial pool sampling strategy showed interesting trends that merit deeper investigation.},
  dimensions={true},
}


@article{Chandra2020AL,
  abbr={Plant Methods},
  title={Active Learning with Point Supervision for Cost-Effective Panicle Detection in Cereal Crops},
  author={Chandra*, Akshay L and Desai*, Sai Vikas and Balasubramanian, Vineeth N and Ninomiya, Seishi and Guo, Wei.},
  abstract={Panicle density of cereal crops such as wheat and sorghum is one of the main components for plant breeders and agronomists in understanding the yield of their crops. To phenotype the panicle density effectively, researchers agree there is a significant need for computer vision-based object detection techniques. Especially in recent times, research in deep learning-based object detection shows promising results in various agricultural studies. However, training such systems usually requires a lot of bounding-box labeled data. Since crops vary by both environmental and genetic conditions, acquisition of huge amount of labeled image datasets for each crop is expensive and time-consuming. Thus, to catalyze the widespread usage of automatic object detection for crop phenotyping, a cost-effective method to develop such automated systems is essential.},
  journal={Plant Methods (BioMed Central)},
  volume={16},
  issue={1},
  year={2020},
  month={March},
  doi={10.1186/s13007-020-00575-8},
  url={https://doi.org/10.1186/s13007-020-00575-8},
  html={https://plantmethods.biomedcentral.com/articles/10.1186/s13007-020-00575-8},
  arxiv={https://arxiv.org/abs/1910.01789},
}


@article{Chandra2020Easy,
  abbr={ECCV Demos},
  title={EasyRFP: An Easy to Use Edge Computing Toolkit for Real-Time Field Phenotyping},
  author={Chandra*, Akshay L and Desai*, Sai Vikas and Masayuki, Hirafuji and Ninomiya, Seishi and Balasubramanian, Vineeth N and Guo, Wei.},
  abstract={We propose EasyRFP, an edge computing toolkit for real-time field phenotyping. Recent advances in deep learning have catalysed rapid progress in high throughput field phenotyping. Much research has been dedicated towards developing accurate and cost effective deep learning models to capture phenotyping traits such as plant stress, yield and plant growth stages. However, there is a shortage of software tools to promote the usage of such intelligent methods among plant phenotyping practitioners and researchers. To bridge this gap, we developed this, a Flask backend, Angular frontend software toolkit. Broadly speaking, our toolkit can be interfaced with a commercial GPU enabled micro computer (such as NVIDIA Jetson) and a digital camera. Precisely, our toolkit can be used to capture images and extract phenotypic traits in both real-time and in scheduled mode. Currently, we support classification, detection and instance segmentation tasks.},
  journal={Extended Abstract at CVPPP & ECCV Academic Demonstrations},
  year={2020},
  month={August},
  video={https://www.youtube.com/watch?v=oAGbpVgPE6U},
  code={https://github.com/lab1055/easy-rfp},
}

@article{Desai2019AnAS,
  abbr={BMVC},
  title={An Adaptive Supervision Framework for Active Learning in Object Detection},
  author={Desai*, Sai Vikas and Chandra*, Akshay L and Guo, Wei and Ninomiya, Seishi and Balasubramanian, Vineeth N},
  abstract={Active learning approaches in computer vision generally involve querying strong labels for data. However, previous works have shown that weak supervision can be effective in training models for vision tasks while greatly reducing annotation costs. Using this knowledge, we propose an adaptive supervision framework for active learning and demonstrate its effectiveness on the task of object detection. Instead of directly querying bounding box annotations (strong labels) for the most informative samples, we first query weak labels and optimize the model. Using a switching condition, the required supervision level can be increased. Our framework requires little to no change in model architecture. Our extensive experiments show that the proposed framework can be used to train good generalizable models with much lesser annotation costs than the state of the art active learning approaches for object detection.},
  journal={British Machine Vision Conference},
  year={2019},
  month={August},
  arxiv={https://arxiv.org/abs/1908.02454},
  poster={bmvc19-poster.pdf}
}
