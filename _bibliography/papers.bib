---
---

@article{Master's Thesis,
  abbr={Master's Thesis},
  author = {Chandra, Akshay L and Nematollahi, Iman and Huang, Chenguang and Welschehold, Tim and Valada, Abhinav},
  title = {Fine-Tuning Diffusion Policies with World Models},
  journal = {Master's Thesis, Robot Learning Lab [Coursework; Not Peer-Reviewed]},
  volume = {2025},
  year = {2025},
  month = {February},
  abstract = {In the behaviour-cloning paradigm, diffusion-based policies (DPs) have recently emerged as a preferred choice for continuous control and robot learning tasks. Much of the adoption is attributed to their efficacy in modelling high-dimensional and multimodal action distributions while showing immense training stability. However, DPs have been limited mainly to the scale and quality of the expert data they fit. To that end, recent works have shown that policy gradient (PG) methods from reinforcement learning (RL) can be helpful in fine-tuning DPs to improve them beyond expert data, with online interactions and sparse task-completion rewards. Specifically, by treating the denoising process as a separate Markov Decision Process (MDP), previous works have applied PG methods to fine-tune DPs. However, RL fine-tuning with millions of environmental interactions for real robots can often be unsafe and unrealistic. We introduce Diffusion Policy Policy Optimisation in World-Models, DPOW, a sample-efficient, real-robot-friendly algorithmic framework for improving DPs offline with learnt dynamics models, i.e. world models. Through experimental investigation, we find that DPOW can fine-tune and improve policies with just offline interactions. We demonstrate stable training and robustness to task difficulty across a range of simulated continuous control manipulation tasks in CALVIN.},
}

@article{ICRA,
  abbr={ICRA},
  author = {Nematollahi, Iman and DeMoss, Branton and Chandra, Akshay L and Hawes, Nick and Burgard, Wolfram and Posner, Ingmar},
  title = {LUMOS: Language-Conditioned Imitation Learning with World Models},
  journal = {IEEE International Conference on Robotics and Automation},
  volume = {2025},
  year = {2025},
  arxiv = {2503.10370},
  code = {https://github.com/nematoli/lumos},
  website = {http://lumos.cs.uni-freiburg.de/},
  abstract = {We introduce LUMOS, a language-conditioned multi-task imitation learning framework for robotics. LUMOS learns skills by practicing them over many long-horizon rollouts in the latent space of a learned world model and transfers these skills zero-shot to a real robot. By learning on-policy in the latent space of the learned world model, our algorithm mitigates policy-induced distribution shift which most offline imitation learning methods suffer from. LUMOS learns from unstructured play data with fewer than 1% hindsight language annotations but is steerable with language commands at test time. We achieve this coherent long-horizon performance by combining latent planning with both image- and language-based hindsight goal relabeling during training, and by optimizing an intrinsic reward defined in the latent space of the world model over multiple time steps, effectively reducing covariate shift. In experiments on the difficult long-horizon CALVIN benchmark, LUMOS outperforms prior learning-based methods with comparable approaches on chained multi-task evaluations. To the best of our knowledge, we are the first to learn a languageconditioned continuous visuomotor control for a real-world robot within an offline world model.},
  preview = {icra25.gif},
}

@article{masters-project,
  abbr={Master's Project},
  author = {Chandra, Akshay L and Nematollahi, Iman and Welschehold, Tim},
  title = {SAC-N-GMM: Robot Skill Refining and Sequencing for Long-Horizon Manipulation Tasks},
  journal = {Master's Project, Robot Learning Lab [Coursework; Not Peer-Reviewed]},
  volume = {2024},
  year = {2024},
  month = {February},
  pdf = {https://akshaychandra.com/assets/pdf/masterproject-report.pdf},
  code = {https://github.com/acl21/sac_n_gmm},
  abstract = {Despite access to expert data, most long-horizon imitation-learning (IL) agents suffer from distribution shifts, compounding errors, and expert dependency. Several previous works show that refining IL agents in the world with reinforcement learning (RL) alleviates some of these problem by making the agents more robust to noisy perception and stochasticity in dynamics with much helpful real-world exposure. SAC-GMM does this efficiently by first learning a task from demonstrations with a classical robotics technique (e.g., Gaussian Mixture Model) and then refines it with a deep RL (Soft Actor-Critic) agent with sparse task-completion rewards. One could further dampen the side effects of long-horizon IL agents by breaking down complex tasks into short-horizon skills. This simplifies the learning goal into a hierarchy of agents, i.e. high-level planning agent (skill sequencer) and low-level control agent (skill executor). To this end, we propose the Soft Actor-Critic-N -Gaussian Mixture Model (SAC-N-GMM), a novel hybrid RL approach that learns to simultaneously refine and sequence a repertoire of low-level skills to perform numerous combinations of long-horizon tasks. Our approach extends SAC-GMM (1) by learning N lowlevel robot skills with Riemannian Manifold GMMs that learn both robot positions and orientations (2) by learning a single RL agent to refine and sequence multiple manifold-aware GMM skills. Extensive evaluations in the CALVIN simulation environment demonstrate that our approach leverages high-dimensional sensory data, minimal expert demonstrations, minimal physical interactions, and sparse task-completion rewards efficiently to achieve superior long-horizon task performance compared to baselines. Code is available at https://github.com/acl21/sac_n_gmm},
  preview = {sac-n-gmm.gif},
}


@article{doi:10.34133/2022/9795275,
  abbr={Plant Phenomics},
  author = {Rawat, Shivangana and Chandra, Akshay L and Desai, Sai Vikas and Balasubramanian, Vineeth N and Ninomiya, Seishi and Guo, Wei},
  title = {How Useful Is Image-Based Active Learning for Plant Organ Segmentation?},
  journal = {Plant Phenomics},
  volume = {2022},
  year = {2022},
  month = {February},
  doi = {10.34133/2022/9795275},
  pdf = {https://spj.science.org/doi/pdf/10.34133/2022/9795275},
  code = {https://github.com/ShivanganaRawat/ALPO_Segmentation},
  html = {https://spj.science.org/doi/abs/10.34133/2022/9795275},
  abstract = {Training deep learning models typically requires a huge amount of labeled data which is expensive to acquire, especially in dense prediction tasks such as semantic segmentation. Moreover, plant phenotyping datasets pose additional challenges of heavy occlusion and varied lighting conditions which makes annotations more time-consuming to obtain. Active learning helps in reducing the annotation cost by selecting samples for labeling which are most informative to the model, thus improving model performance with fewer annotations. Active learning for semantic segmentation has been well studied on datasets such as PASCAL VOC and Cityscapes. However, its effectiveness on plant datasets has not received much importance. To bridge this gap, we empirically study and benchmark the effectiveness of four uncertainty-based active learning strategies on three natural plant organ segmentation datasets. We also study their behaviour in response to variations in training configurations in terms of augmentations used, the scale of training images, active learning batch sizes, and train-validation set splits.},
  preview = {plantphenomics22.png},
}

@article{pmlr-v148-chandra21a,
  abbr={PMLR/NeurIPS W},
  title = {On Initial Pools for Deep Active Learning},
  author = {Chandra*, Akshay L and Desai*, Sai Vikas and Devaguptapu*, Chaitanya and Balasubramanian, Vineeth N.},
  journal = {NeurIPS 2020 Workshop on Pre-registration in Machine Learning},
  pages = {14-32},
  year = {2021},
  editor = {Bertinetto, Luca and Henriques, João F. and Albanie, Samuel and Paganini, Michela and Varol, Gül},
  volume = {148},
  series = {Proceedings of Machine Learning Research},
  month = {December},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v148/chandra21a/chandra21a.pdf},
  code = {https://github.com/acl21/init-pools-dal},
  html = {https://proceedings.mlr.press/v148/chandra21a.html},
  abstract = {Active Learning (AL) techniques aim to minimize the training data required to train a model for a given task. Pool-based AL techniques start with a small initial labeled pool and then iteratively pick batches of the most informative samples for labeling. Generally, the initial pool is sampled randomly and labeled to seed the AL iterations. While recent studies have focused on evaluating the robustness of various query functions in AL, little to no attention has been given to the design of the initial labeled pool for deep active learning. Given the recent successes of learning representations in self-supervised/unsupervised ways, we study if an intelligently sampled initial labeled pool can improve deep AL performance. We investigate the effect of intelligently sampled initial labeled pools, including the use of self-supervised and unsupervised strategies, on deep AL methods. The setup, hypotheses, methodology, and implementation details were evaluated by peer review before experiments were conducted. Experimental results could not conclusively prove that intelligently sampled initial pools are better for AL than random initial pools in the long run, although a Variational Autoencoder-based initial pool sampling strategy showed interesting trends that merit deeper investigation.},
  dimensions = {true},
  preview = {pmlr21.png},
}


@article{Chandra2020AL,
  abbr={Plant Methods},
  title={Active Learning with Point Supervision for Cost-Effective Panicle Detection in Cereal Crops},
  author={Chandra*, Akshay L and Desai*, Sai Vikas and Balasubramanian, Vineeth N and Ninomiya, Seishi and Guo, Wei.},
  abstract={Panicle density of cereal crops such as wheat and sorghum is one of the main components for plant breeders and agronomists in understanding the yield of their crops. To phenotype the panicle density effectively, researchers agree there is a significant need for computer vision-based object detection techniques. Especially in recent times, research in deep learning-based object detection shows promising results in various agricultural studies. However, training such systems usually requires a lot of bounding-box labeled data. Since crops vary by both environmental and genetic conditions, acquisition of huge amount of labeled image datasets for each crop is expensive and time-consuming. Thus, to catalyze the widespread usage of automatic object detection for crop phenotyping, a cost-effective method to develop such automated systems is essential.},
  journal={Plant Methods (BioMed Central)},
  volume={16},
  issue={1},
  year={2020},
  month={March},
  doi={10.1186/s13007-020-00575-8},
  url={https://doi.org/10.1186/s13007-020-00575-8},
  arxiv={1910.01789},
  html={https://plantmethods.biomedcentral.com/articles/10.1186/s13007-020-00575-8},
  preview={plantmethods20.png}
}


@article{Chandra2020Easy,
  abbr={CVPPP/ECCV Demos},
  title={EasyRFP: An Easy to Use Edge Computing Toolkit for Real-Time Field Phenotyping},
  author={Chandra*, Akshay L and Desai*, Sai Vikas and Masayuki, Hirafuji and Ninomiya, Seishi and Balasubramanian, Vineeth N and Guo, Wei.},
  abstract={We propose EasyRFP, an edge computing toolkit for real-time field phenotyping. Recent advances in deep learning have catalysed rapid progress in high throughput field phenotyping. Much research has been dedicated towards developing accurate and cost effective deep learning models to capture phenotyping traits such as plant stress, yield and plant growth stages. However, there is a shortage of software tools to promote the usage of such intelligent methods among plant phenotyping practitioners and researchers. To bridge this gap, we developed this, a Flask backend, Angular frontend software toolkit. Broadly speaking, our toolkit can be interfaced with a commercial GPU enabled micro computer (such as NVIDIA Jetson) and a digital camera. Precisely, our toolkit can be used to capture images and extract phenotypic traits in both real-time and in scheduled mode. Currently, we support classification, detection and instance segmentation tasks.},
  journal={Extended Abstract at CVPPP & ECCV Academic Demonstrations},
  year={2020},
  month={August},
  code={https://github.com/lab1055/easy-rfp},
  video={https://www.youtube.com/watch?v=oAGbpVgPE6U},
  preview={cvppp20.png},
}

@article{Desai2019AnAS,
  abbr={BMVC},
  title={An Adaptive Supervision Framework for Active Learning in Object Detection},
  author={Desai*, Sai Vikas and Chandra*, Akshay L and Guo, Wei and Ninomiya, Seishi and Balasubramanian, Vineeth N},
  abstract={Active learning approaches in computer vision generally involve querying strong labels for data. However, previous works have shown that weak supervision can be effective in training models for vision tasks while greatly reducing annotation costs. Using this knowledge, we propose an adaptive supervision framework for active learning and demonstrate its effectiveness on the task of object detection. Instead of directly querying bounding box annotations (strong labels) for the most informative samples, we first query weak labels and optimize the model. Using a switching condition, the required supervision level can be increased. Our framework requires little to no change in model architecture. Our extensive experiments show that the proposed framework can be used to train good generalizable models with much lesser annotation costs than the state of the art active learning approaches for object detection.},
  journal={British Machine Vision Conference},
  year={2019},
  month={August},
  arxiv={1908.02454},
  poster={bmvc19-poster.pdf},
  preview={bmvc19.png}
}
