<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h4>A quick look at some basic stuff essential to understand how parameters are learned.</h4> <p>This is an optional read for the 5 part series I wrote on learning parameters. In this post, you will find some basic stuff you’d need to understand my other blog posts on how deep neural networks learn their parameters better. You can check out all the posts in the <strong><em>Learning Parameters </em></strong>series by clicking on the kicker tag at the top of this post.</p> <p>We will briefly look at the following topics:</p> <ol> <li>Multivariable Functions</li> <li>Local Minimum vs. Global Minimum</li> <li>Understanding The Gradient</li> <li>Cost or Loss Function</li> <li>Contour Maps</li> </ol> <h3>1. Multivariable Functions</h3> <p>A multivariable function is just a function whose input and/or output is made up of multiple numbers/variables. E.g., <em>f(x, y) = z= x² + y².</em></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/482/1*4M10mQ0R-y9sFymnIPdvpw.gif"><figcaption>Fig1. z = x² + y² graph by Google. <strong>Image Source:</strong> Google the equation.</figcaption></figure> <p>Functions with multiple outputs are also called multivariable functions, but they are irrelevant here.</p> <h3>3. Understanding The Gradient</h3> <p>The term “gradient” is just a fancy way of referring to derivatives of multivariable functions. While a derivative can be defined for functions of a single variable, for functions of several variables the gradient takes its place. The gradient is a vector-valued function while the derivative is scalar-valued.</p> <p>The derivative of a single variable function, denoted by <strong><em>f’(x)</em></strong><em> </em>or<em> </em><strong><em>df</em>/<em>dx</em></strong><em>, </em>tells us how much the function value changes with a unit change in the input. But if a function takes multiple inputs <strong><em>x</em></strong><em> </em>and <strong><em>y</em></strong>, we need to know how much the value of the function changes with respect to <strong><em>x</em> </strong>and <strong><em>y</em></strong> individually i.e., how much <strong><em>f(x,y)</em></strong> changes when <strong><em>x</em></strong> changes a teeny-tiny bit while keeping <strong><em>y</em></strong> constant and also how much it changes when <strong><em>y</em></strong> changes a teeny-tiny bit while keeping <strong><em>x</em></strong><em> </em>constant. These are called <em>partial derivatives </em>of the function often denoted by <strong>∂<em>f</em>/<em>∂x</em></strong><em> </em>and<em> </em><strong><em>∂f</em>/∂y </strong>respectively and when you put these two innocent scalars in a vector, denoted by ∇<strong><em>f</em></strong><em>,</em><strong><em> </em></strong>like the following, you get what we call the hero of calculus, the gradient!!</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/184/1*XJaTT0wevEDbtyYkKi-0Lg.png"></figure> <h4>Properties Of The Gradient</h4> <p>There are many more properties but let us just focus on two necessary ones:</p> <ul> <li>A gradient points in the direction of greatest increase of a function.</li> <li>It is zero at a local maximum or local minimum (because there is no single direction of increase)</li> </ul> <p>The first property says that if you imagine standing at a point <em>(x, y)</em> in the input space of <em>f</em>, the vector ∇<em>f</em>(<em>x</em>, <em>y)</em> tells you which direction you should travel to increase the value of <em>f</em> most rapidly. This obviously generalizes to N dims. When I first learned this in school, it was not at all obvious why this would be the case, but check out these <a href="https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives#partial-derivative-and-gradient-articles" rel="external nofollow noopener" target="_blank">set of videos</a> on Khan Academy to know more about this.</p> <p>To understand the second property, we need to know what a derivate is, visually. The derivate of a line is the slope of the line, the derivative of a curve at any point is the slope of the tangent to that curve at that point.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/229/1*ugvwTNWM34pDwvmiq3D4TQ.gif"><figcaption><strong>y(x)=x²-3x+3</strong> with the tangent line through the point <strong>(3,3)</strong>. <strong>Image Source:</strong> [5]</figcaption></figure> <p>For functions of two variables (a surface), there are many lines tangent to the surface at a given point. If we have a nice enough function, all of these lines form a plane called the tangent plane to the surface at the point.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/315/1*Up-PuWmM_gGii1cdbpkwbQ.gif"><figcaption>The tangent plane to the surface <strong><em>z=-x²-y²</em></strong> at the point <strong>(0,2)</strong>. <strong>Image Source:</strong> [5]</figcaption></figure> <p>I am sure you can convince yourself that this plane at the maximum of the surface, i.e., at the tip of the surface, will be parallel to the <strong><em>XY</em></strong>-plane Which suggests that the tangent’s slope is 0 at maximum. If you can’t, look at the following.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*OJIB1w0M7XfesTIWix8Xcw.png"><figcaption>The tangent planes to the surfaces<strong> z=-x²-y²</strong> and <strong>z=x²+y²</strong> at their maximum and minimum respectively.</figcaption></figure> <h3>3. Cost/Loss Function</h3> <p>Arguably, the value you’d want to care about the most while training a neural network is the loss/cost. It measures how “good” or “bad” your model is fitting the data. Any GD like algorithm’s primary goal is to find the set of parameters that produce the least cost. All the drama around references like “finding the minimum,” “walking on the error surface” are just talking about adjusting the parameters in a way we end up with the least possible cost function value. You could think of a cost function as a multivariable function with model weights as the parameters. Try not to think beyond 2 parameters — you know why!</p> <p>There are many ways you can frame your loss function. Different types of problems (classification &amp; regression) can have different types of loss functions framed that best represent the performance of the models, which is for another day, another post. For now, this intuition is good enough to understand the rest of the story. You can watch this video [6] by Siraj Raval to know more about loss functions.</p> <h3>4. Local Minimum vs. Global Minimum</h3> <p>In figure 1, how many “minimums” do you see? I see just one. How nice! If your loss function looked like that, you could start your descent from anywhere on the graph (I mean, keep changing your parameters) with a reliable guide alongside (ahem Gradient Descent ahem), there is a good chance you’d end up at that sweet dark green spot on the surface. Too bad, the error surfaces you’d end up while optimizing even the smallest networks could be bumpier and in some sense, scarier.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/351/1*XrL0tp9rHSeN5SosuAvC_g.png"><figcaption>Fig2. Not so friendly cost function eh? <strong>Image Source: </strong>[1]</figcaption></figure> <p>In many real-world cases, the minimum values you are going attain depend significantly on the point at which you start the descent. If you started your descent near a valley, the GD algorithm would most definitely force you to go into that valley (a local minimum), but the real minimum (global minimum) could be somewhere else on the surface.</p> <p>Take a look at the cost function of the two of the most popular neural networks, VGG-56 and VGG-110.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/882/1*YOkeatQyMDHEK9KLV4Rmgw.png"><figcaption>Fig3. “Bumpier” and “scarier” cost functions of VGG-56 and VGG-110 networks. <strong>Image Source:</strong> [3]</figcaption></figure> <blockquote>Pause and ponder!! <br>How can you possibly visualise a “big” network’s cost function in 3D? Big networks often have millions of parameters so how is this even possible? Read the paper linked in the references to find out.</blockquote> <h3>5. Contours</h3> <p>Visualizing things in 3-D can sometimes be a bit cumbersome, and contour maps come in as a handy alternative for representing functions with 2-D input and 1-D output. It is easier to explain it graphically than in text.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*x729LmFP5y9fI6aePt249Q.png"><figcaption>Fig4. Step Wise Illustration Of Contour Mapping Process. <strong>Images Taken From </strong>[7]</figcaption></figure> <h4>The Contour Mapping Process</h4> <p><strong>Step 1: </strong>Start with the graph of the function.<br><strong>Step 2: </strong>Slice it up in regular intervals with planes parallel to the input plane at different heights.<br><strong>Step 3: </strong>Mark all the places on the graph the plane cuts through. <br><strong>Step 4: </strong>Project the markings on a 2-D plane, label the corresponding plane heights and map them accordingly.</p> <h4>Key Takeaways</h4> <ul> <li>A small distance between the contours indicates a steep slope along that direction</li> <li>A large distance between the contours indicates a gentle slope along that direction</li> </ul> <figure><img alt="" src="https://cdn-images-1.medium.com/max/262/1*bsgrLfNTzZ7LUCA0T89onA.png"><figcaption>Fig5.<strong> Image Source:</strong> Wikipedia</figcaption></figure> <h4>Test Your Understanding</h4> <p>It is alright if you are still unable to comprehend the concept of contour maps completely. You can test your understanding by guessing the 3-D plots (without looking at the solution present on the right column of Figure 6) for the following contour maps.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*k65Tvna-KznaCgyu6LOCIg.png"><figcaption>Fig6. Test Your Understanding! <strong>Image Source: </strong>[8]</figcaption></figure> <p>Please read this brilliant article [7] by Khan Academy to know more about Contour Maps.</p> <p>Check out the next post in this series at :</p> <ul><li><a href="https://towardsdatascience.com/learning-parameters-part-1-eb3e8bb9ffbb" rel="external nofollow noopener" target="_blank">Learning Parameters, Part-1: Gradient Descent.</a></li></ul> <h3>References</h3> <ol> <li> <a href="https://math.oregonstate.edu/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/tangent/tangent.html" rel="external nofollow noopener" target="_blank">The hard thing about deep learning</a>, <a href="https://www.oreilly.com/people/4a99a-reza-zadeh" rel="external nofollow noopener" target="_blank">Reza Zadeh</a>.</li> <li> <a href="https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/" rel="external nofollow noopener" target="_blank">Intro to optimization in deep learning: Gradient Descent</a>, <a href="https://blog.paperspace.com/author/ayoosh/" rel="external nofollow noopener" target="_blank">Ayoosh Kathuria</a>.</li> <li> <a href="https://www.cs.umd.edu/~tomg/projects/landscapes/" rel="external nofollow noopener" target="_blank">Visualizing the Loss Landscape of Neural Nets</a>, CS-UMD.</li> <li> <a href="http://ruder.io/optimizing-gradient-descent/index.html" rel="external nofollow noopener" target="_blank">An overview of gradient descent optimization algorithms</a>, <a href="http://ruder.io/" rel="external nofollow noopener" target="_blank">Sebastian Ruder</a>.</li> <li> <a href="https://math.oregonstate.edu/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/tangent/tangent.html" rel="external nofollow noopener" target="_blank">Tangent Planes And Total Differentials</a>, Oregon State University.</li> <li> <a href="https://www.youtube.com/watch?v=IVVVjBSk9N0" rel="external nofollow noopener" target="_blank">Loss Functions Explained</a>, Siraj Raval.</li> <li> <a href="https://www.khanacademy.org/math/multivariable-calculus/thinking-about-multivariable-function/ways-to-represent-multivariable-functions/a/contour-maps" rel="external nofollow noopener" target="_blank">Contour Maps (article)</a>, Khan Academy.</li> <li> <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html" rel="external nofollow noopener" target="_blank">CS7015: Deep Learning, Indian Institute Of Technology</a>, Madras.</li> </ol> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5cfffd647bdc" width="1" height="1" alt="">&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/towards-data-science/learning-parameters-part-0-5cfffd647bdc" rel="external nofollow noopener" target="_blank">Learning Parameters, Part 0: Basic Stuff</a> was originally published in <a href="https://medium.com/towards-data-science" rel="external nofollow noopener" target="_blank">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p> </body></html>