<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://akshaychandra.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://akshaychandra.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-07T15:31:40+00:00</updated><id>https://akshaychandra.com/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">[3/3] Quaternion Rotation Operator</title><link href="https://akshaychandra.com/blog/2023/quat-rot-op2/" rel="alternate" type="text/html" title="[3/3] Quaternion Rotation Operator"/><published>2023-10-27T00:00:00+00:00</published><updated>2023-10-27T00:00:00+00:00</updated><id>https://akshaychandra.com/blog/2023/quat-rot-op2</id><content type="html" xml:base="https://akshaychandra.com/blog/2023/quat-rot-op2/"><![CDATA[<blockquote> <p><strong>Citation Note:</strong> I have borrowed this article’s content from Jack B. Kuipers’ seminal 1999 book <d-cite key="kuipers1999quaternions"></d-cite> on quaternions.</p> </blockquote> <blockquote> <p>As an admirer of the book’s writing style, I submit that you are probably better off referring to Chapter 5 of the book. My motivation to write this regardless is twofold - to provide robotics practitioners with a one-stop-shop entry point to quaternions and challenge/improve my understanding of them. I claim no expertise in this topic but found it so fascinating that I decided to write about it.</p> </blockquote> <blockquote> <p><strong>Prerequisites:</strong> This is [3/3] article in my series on quaternions. For this article, I assume readers’ familiarity with basic quaternion algebra <d-cite key="quat-basics"></d-cite> and some quaternion variants I discussed in <d-cite key="quat-rot-op1"></d-cite>.</p> </blockquote> <hr/> <p>Earlier, we saw a great deal of evidence that quaternions indeed can represent \(\mathbb{R}^3\) rotations. With the checked list in mind, we can now safely define the quaternion rotation operator and apply some tests to understand its geometric effects on \(\mathbb{R}^3\) vectors. All quaternions you see in this article are to be assumed units.</p> <h2 id="quaternion-rotation-operator-definition">Quaternion Rotation Operator: Definition</h2> <p>Let \(\mathbf{q}\) be a unit quaternion, and \(\vec{v}\) be a vector in \(\mathbb{R}^3\) (pure quaternion); we define two rotation operators as follows:</p> \[\begin{aligned} R_{\mathbf{q}}(\vec{v}) &amp;= \mathbf{q} \star \vec{v} \star \mathbf{q}^{\ast} \\ R_{\mathbf{q}^{\ast}}(\vec{v}) &amp;= \mathbf{q}^{\ast} \star \vec{v} \star \mathbf{q} \end{aligned}\] <p>For comparison, writing out the operator algorithm will be helpful.</p> \[\begin{aligned} R_{\mathbf{q}}(\vec{v}) &amp;= \mathbf{q} \star \vec{v} \star \mathbf{q}^{\ast} \\ &amp;= (2q_0^2-1)\vec{v} + 2(\vec{q}\cdot \vec{v})\vec{q} + 2q_0(\vec{q} \times \vec{v}) \\ R_{\mathbf{q}^{\ast}}(\vec{v}) &amp;= \mathbf{q}^{\ast} \star \vec{v} \star \mathbf{q} \\ &amp;= (q_0^2-\Vert \vec{q} \Vert^2)\vec{v} + 2(\vec{q}\cdot \vec{v})\vec{q} + 2q_0(\vec{q} \times \vec{v}) \end{aligned}\] <p>Without formal proof, I claim that these operators indeed rotate \(\vec{v}\) in \(\mathbb{R}^3\). Through some carefully designed tests, I hope to convince you on the same by answering the following key questions about \(R_{\mathbf{q}}\):</p> <ul> <li>What is the direction of rotation?</li> <li>What is the axis of rotation?</li> <li>What is the angle of rotation?</li> <li>What is the difference between \(R_{\mathbf{q}}\) and \(R_{\mathbf{q}^{\ast}}\)?</li> </ul> <p>Let us start by reverse engineering the output of \(R_{\mathbf{q}}(\mathbf{v})\) to answer the questions.</p> <h2 id="incremental-test">Incremental Test</h2> <p>For this test, let us make our lives easy and work with <em>simple</em> quaternions and <em>simple</em> vectors that are easy to visualise in our heads. Suppose that the unit quaternion \(\mathbf{q}\) in \(R_{\mathbf{q}}(\vec{v})\) has a basis vector</p> \[\vec{u} = 0i + 0j + 1k = k \quad (\text{or }\left[\begin{matrix} 0 \\ 0 \\ 1\end{matrix}\right])\] <p>where \(\{i, j, k\}\) are the standard basis vectors in \(\mathbb{R}^3\), that define the coordinate frame. Let us now look at \(\mathbf{q}\) in polar form (recall section <em>Polar Form</em> from <d-cite key="quat-rot-op1"></d-cite>):</p> \[\mathbf{q} = \cos \theta + k \sin \theta\] <p>Assume that the associated angle \(\theta\) is a very small positive angle. This assumption is helpful when comparing the input vector with the operator’s output vector. We want to verify if \(R_{\mathbf{q}}(\vec{v})\) merely “tweaks” the input vector when the associated angle is a very small positive value. Conveniently, for very small positive angles, we can round things up nicely, i.e., \(\cos \theta \approx 1\) and \(\sin \theta \approx \theta\) so the quaternion \(\mathbf{q}\) may be re-written as</p> \[\mathbf{q} \approx 1 + k\theta\] <p>In the spirit of simplicity, suppose that you want to rotate another basis vector \(\vec{v} = 1i + 0j + 0k = i\) (or \(\left[\begin{matrix} 1 \\ 0 \\ 0\end{matrix}\right]\)). Let us see what the operator \(R_{\mathbf{q}}(\vec{v})\) outputs for this carefully chosen \(\mathbf{q}\) and \(\vec{v}\):</p> \[\begin{aligned} \vec{w} &amp;= R_{\mathbf{q}}(\vec{v}) = \mathbf{q} \star i \star \mathbf{q}^{\ast} \\ &amp;= (1+k\theta)(i)(1-k\theta) \\ &amp;= (1+k\theta)(i+j\theta) \\ \vec{w} &amp;= i + 2\theta j \quad (\text{or }\left[\begin{matrix} 1 \\ 2\theta \\ 0\end{matrix}\right]) \end{aligned}\] <p>We can interpret this result to mean that the input vector \(i\) has been “tweaked” by <em>some</em> angle to produce the output vector \(i + 2\theta j\). Firstly, for completeness, let us examine the length of \(\vec{w}\)</p> \[\Vert \vec{w} \Vert = \sqrt{(1)^2 + (2\theta)^2} \approx 1 \quad (\text{Since }\theta \approx 0)\] <p>The length of the \(\vec{w}\) is still \(1\) (well almost, if you ignore the very small value \(\theta^2\))<d-footnote>Note that we have no restriction on the length of the vector to be rotated, just that the output vector's length _should not_ change after rotation and it does not so this is good news. </d-footnote>. Now, lets think about the angle between <em>rotated image</em> \(\vec{w}\) and \(\vec{v}\). It helps to mentally visualize this rotation as a vector that was earlier pointing at \(i\) (or \(\left[\begin{matrix} 1 \\ 0 \\ 0\end{matrix}\right]\)) and is now pointing at \(i+2\theta j\) (or \(\left[\begin{matrix} 1 \\ 2\theta \\ 0\end{matrix}\right]\)). Geometrically, it so appears that \(i\) is rotated <em>counter-clockwise</em> about the axis \(k\) by \(2\theta\) angle. Let us verify this by checking the angle of rotation \(\alpha\) between \(\vec{w}\) and \(\vec{v}\), which can be given by:</p> \[\begin{aligned} \tan \alpha &amp;= \frac{\Vert w \times v \Vert}{(w \cdot v)} \\ &amp;= \frac{\Vert i + 2\theta j \times i \Vert}{(i+2\theta j) \cdot (i)} \\ &amp;= \frac{\Vert 2\theta k \Vert}{(1 \cdot 1 + 2\theta \cdot 0 + 0 \cdot 0)}\\ &amp;= \frac{2\theta}{1} \quad (\text{Geometrically, just } \frac{\text{opposite}}{\text{adjacent}})\\ \alpha &amp;\approx 2\theta \quad (\text{Since } \tan \alpha \approx \alpha \text{ when } \alpha \approx 0^+) \\ \alpha &amp;\approx\text{A very small positive angle} \end{aligned}\] <p>which seems fair for the choice of a very small positive angle \(\theta\). Despite some (potentially uneasy) approximations, we now have a pretty good idea of the direction, axis and angle of rotation associated with \(R_{\mathbf{q}}\). The general rule goes as follows:</p> <blockquote> <p>Given a unit quaternion \(\mathbf{q} = \cos \theta + \vec{u} \sin \theta\) and a vector \(\vec{v}\) in \(\mathbb{R}^3\), \(R_{\mathbf{q}}(\vec{v})\) rotates \(\vec{v}\) in counter-clockwise direction about the axis of \(\vec{u}\) by angle \(2\theta\).</p> </blockquote> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/quat-rot-viz-480.webp 480w,/assets/img/blog/quat-rot-viz-800.webp 800w,/assets/img/blog/quat-rot-viz-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/quat-rot-viz.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>See the figure above for clarity. We can further verify this visually (at least the axis and direction of rotation) for varying \(\theta\) values in Ben Eater’s interactive quaternion visualisation<d-cite key="eater-quat-viz"></d-cite>, see the following animation.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/quat-rot-viz-gif-480.webp 480w,/assets/img/blog/quat-rot-viz-gif-800.webp 800w,/assets/img/blog/quat-rot-viz-gif-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/quat-rot-viz-gif.gif" class="rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">The visualisation shows rotation from the above example but with varying associated angle.</figcaption> </figure> <p>I encourage you to verify other rotations, say when \(\vec{u} = i\) or \(j\). If you did verify, for the case \(\vec{u} = i\), you will have seen no rotation at all. This implies, perhaps obviously, that any vector \(\vec{v}\) which lies <em>on the axis of rotation</em> \(\vec{u}\) must be <em>invariant</em> under \(R_{\mathbf{q}}(\vec{v})\).</p> <h2 id="angle-test">Angle Test</h2> <p>When I first saw the incremental test, I was left uneasy and sceptical of the angle of rotation due to the approximations made. But we can be sure of the claims made on the angle of rotation with a simple angle test. Let us choose a unit quaternion with the associated angle \(\theta=\frac{\pi}{6}\) while keeping the axis of rotation \(\vec{u}\) as the same basis vector \(k\). Then we have the following quaternion</p> \[\begin{aligned} \mathbf{q} = \cos \theta + k \sin \theta &amp;= \cos (\frac{\pi}{6}) + k \sin (\frac{\pi}{6}) \\ &amp;= \frac{\sqrt{3}}{2} + \frac{1}{2} k \end{aligned}\] <p>Let us apply the operator \(R_{\mathbf{q}}(\vec{v})\) on the same basis vector \(\vec{v} = 1i + 0j + 0k = i\). We have</p> \[\begin{aligned} \vec{w} &amp;= R_{\mathbf{q}}(\vec{v}) = (\frac{\sqrt{3}}{2} + \frac{1}{2} k)(i)(\frac{\sqrt{3}}{2} - \frac{1}{2} k) \\ &amp;= (\frac{\sqrt{3}}{2} i + \frac{1}{2} j)(\frac{\sqrt{3}}{2} - \frac{1}{2} k) \\ &amp;= \frac{3}{4} i + \frac{\sqrt{3}}{4} j + \frac{\sqrt{3}}{4} j - \frac{1}{4} i \\ &amp;= \frac{1}{2} i + \frac{\sqrt{3}}{2} j \end{aligned}\] <p>As seen earlier, the angle between \(\frac{1}{2} i + \frac{\sqrt{3}}{2} j\) and \(i\) is given by</p> \[\begin{aligned} \tan \alpha &amp;= \frac{\frac{\sqrt{3}}{2}}{\frac{1}{2}} \quad (\frac{\text{opposite}}{\text{adjacent}}) \\ &amp;= \sqrt{3} \\ \alpha &amp;= \arctan \sqrt{3} \\ \alpha &amp;= \frac{\pi}{3} \quad (= 2\theta) \end{aligned}\] <p>We can now confirm that the angle of rotation for a unit quaternion \(\mathbf{q}\) with an associated angle \(\theta\) is indeed \(2\theta\). Always choose a quaternion that has an associate angle half that of your target rotation angle.</p> <h2 id="rotation-perspective">Rotation Perspective</h2> <p>At this point, we have everything we need to geometrically compare \(R_{\mathbf{q}}(\vec{v})\) and \(R_{\mathbf{q}^{\ast}}(\vec{v})\). Consider the example from the <em>Angle Test</em>, there are two possible interpretations of \(\vec{w}\). One is that \(\vec{v}\) has rotated about \(k\)-axis by \(+\frac{\pi}{3}\) angle that is in a counter-clockwise direction with a fixed coordinate frame \(\{i, j, k\}\), this is called <em>point</em> rotation. Another one is that the coordinate frame \(\{i, j, k\}\) has rotated about \(k\)-axis by \(-\frac{\pi}{3}\) angle that is in clockwise direction with a fixed vector \(\vec{v}\), this is called <em>frame</em> rotation. Which of these two perspectives is to be preferred in a given application is usually a subjective matter - a decision made by the practitioner. This is precisely where the conjugate rotation operator \(R_{\mathbf{q}^{\ast}}(\vec{v})\) comes into play.</p> <p>One can easily verify for the example in the <em>Incremental Test</em>, where \(\mathbf{q} \approx 1 + k\theta\) and \(\vec{v} = 1i + 0j + 0k = i\), applying the conjugate rotation operator \(R_{\mathbf{q}^{\ast}}(\vec{v})\) on \(\vec{v}\) would yield the following:</p> \[\vec{w}^{\ast} = R_{\mathbf{q}^{\ast}}(\vec{v}) = 1 - 2\theta j\] <p>Comparing this with the \(\vec{w} = 1 + 2\theta j\) suggests that the difference between \(R_{\mathbf{q}}(\vec{v})\) and \(R_{\mathbf{q}^{\ast}}(\vec{v})\) is simply the direction of rotation. One must be careful here, however, as seen in section <em>Polar Form</em> of <d-cite key="quat-rot-op1"></d-cite>, \(\theta\) has to restrict to the domain \((-\pi, \pi]\). So \(\theta\) can be both negative and positive, which makes it very difficult to differentiate between these two operators. Basically, \(R_{\mathbf{q}}(\vec{v})\) can do what \(R_{\mathbf{q}^{\ast}}(\vec{v})\) does with an appropriate choice of \(\theta\) i.e., replace \(\theta\) by \(-\theta\) in \(\mathbf{q}\) and you go from \(R_{\mathbf{q}}(\vec{v})\) to \(R_{\mathbf{q}^{\ast}}(\vec{v})\). In a nutshell, rotation perspective, personal preference, and even library conventions often decide the use of one operator over the other in a given application. It is important to note that both are mathematically equivalent and can represent the same rotations.</p> <h2 id="quaternion-rotation-operator-theorems">Quaternion Rotation Operator: Theorems</h2> <p>I present to you, without formal proof, the two theorems that summarise the two quaternion rotation operators \(R_{\mathbf{q}}(\vec{v})\) and \(R_{\mathbf{q}^{\ast}}(\vec{v})\).</p> <blockquote> <p><strong>Theorem 1:</strong> For any unit quaternion \(\mathbf{q} = q_0 + \vec{q} = \cos \theta + \vec{u} \sin \theta\) and for any vector \(\vec{v} \in \mathbb{R}^3\), the action of the operator \(R_{\mathbf{q}}(\vec{v}) = \mathbf{q} \star \vec{v} \star \mathbf{q}^{\ast}\) on \(\vec{v}\) may be interpreted geometrically as a rotation of the vector \(\vec{v}\) through an angle \(2\theta\) about \(\vec{q}\) or \(\vec{u}\) as the axis of rotation.</p> </blockquote> <blockquote> <p><strong>Theorem 2:</strong> For any unit quaternion \(\mathbf{q} = q_0 + \vec{q} = \cos \theta + \vec{u} \sin \theta\) and for any vector \(\vec{v} \in \mathbb{R}^3\), the action of the operator \(R_{\mathbf{q}^{\ast}}(\vec{v}) = \mathbf{q}^{\ast} \star \vec{v} \star \mathbf{q}\) on \(\vec{v}\) may be interpreted geometrically</p> </blockquote> <blockquote> <ul> <li>as a rotation of the coordinate frame with respect to the vector \(\vec{v}\) through an angle \(2\theta\) about \(\vec{q}\) or \(\vec{u}\) as the axis, or,</li> <li>an opposite rotation of the vector \(\vec{v}\) with respect to the coordinate frame through an angle \(2\theta\) about \(\vec{q}\) or \(\vec{u}\) as the axis.</li> </ul> </blockquote> <p>While the conjectural proof above may be intuitive and perhaps sufficient for some readers, I refer the more curious to Chapter 15.15 of <d-cite key="kuipers1999quaternions"></d-cite> for the full formal proofs of Theorem 1 and 2.</p> <h2 id="quaternion-operator-sequences">Quaternion Operator Sequences</h2> <p>We often find ourselves <em>applying</em> a sequence of rotations to the robot in many applications. To that end, it helps to know that the quaternion operators elegantly handle rotation sequences.</p> <blockquote> <p><strong>Theorem 3:</strong> Suppose that \(\mathbf{p}\) and \(\mathbf{q}\) are unit quaternions which define the quaternion rotation operators \(R_{\mathbf{p}}(\vec{u}) = \mathbf{p} \star \vec{u} \star \mathbf{p}^{\ast}\) and \(R_{\mathbf{q}}(\vec{v}) = \mathbf{q} \star \vec{v} \star \mathbf{q}^{\ast}\). Then the quaternion product \(\mathbf{q} \star \mathbf{p}\) defines a quaternion rotation operator \(R_{\mathbf{q} \star \mathbf{p}}\) which represents a sequence of operators, \(R_{\mathbf{p}}\) followed by \(R_{\mathbf{q}}\). The axis and the angle of rotation are those represented by the quaternion product \(\mathbf{q} \star \mathbf{p}\).</p> </blockquote> <p>The proof for which is easy and straightforward (for clarity, recall <em>Complex Conjugate</em> rules from <d-cite key="quat-basics"></d-cite>):</p> \[\begin{aligned} R_{\mathbf{q}}(R_{\mathbf{p}}(\vec{u})) &amp;= R_{\mathbf{q}}(\mathbf{p} \star \vec{u} \star \mathbf{p}^{\ast}) \\ &amp;= \mathbf{q} \star (\mathbf{p} \star \vec{u} \star \mathbf{p}^{\ast}) \star \mathbf{q}^{\ast} \\ &amp;= (\mathbf{q} \star \mathbf{p}) \star \vec{u} \star (\mathbf{q} \star \mathbf{p})^{\ast} \\ &amp;= R_{\mathbf{q} \star \mathbf{p}}(\vec{u}) \end{aligned}\] <p>Without much effort, one can easily extend Theorem 3 to the \(R_{\mathbf{q}^{\ast}}\) case.</p> <blockquote> <p><strong>Theorem 4:</strong> Suppose that \(\mathbf{p}\) and \(\mathbf{q}\) are unit quaternions which define the quaternion rotation operators \(R_{\mathbf{p}^{\ast}}(\vec{u}) = \mathbf{p}^{\ast} \star \vec{u} \star \mathbf{p}\) and \(R_{\mathbf{q}^{\ast}}(\vec{v}) = \mathbf{q}^{\ast} \star \vec{v} \star \mathbf{q}\). Then the quaternion product \(\mathbf{p} \star \mathbf{q}\) defines a quaternion rotation operator \(R_{(\mathbf{p} \star \mathbf{q})^{\ast}}\) which represents a sequence of operators, \(R_{\mathbf{p}^{\ast}}\) followed by \(R_{\mathbf{q}^{\ast}}\). The axis and the angle of rotation are those represented by the quaternion product \(\mathbf{p} \star \mathbf{q}\).</p> </blockquote> <p>The proof for Theorem 4 follows the same line of argument as that of Theorem 3’s so I leave that to you. To that end, I refer the readers to Chapter 15.16 of <d-cite key="kuipers1999quaternions"></d-cite> for more discussion and examples on this.</p> <h2 id="conclusion">Conclusion</h2> <p>This concludes my attempt to introduce robotics practitioners to quaternions and their rotation operators. Perhaps now is a good time to watch Grant Sanderson, a.k.a Mathematics YouTuber 3Blue1Brown’s videos on quaternions<d-cite key="3b1b"></d-cite>.</p> <p>As we conclude this journey, I urge you to venture further into the realm of quaternions as a Riemannian manifold. Riemannian manifolds are mathematical spaces that, like quaternions, possess local and global geometrical properties. They extend our understanding of spaces beyond the familiar Euclidean world, allowing us to model curved surfaces. To that end, I want to emphasize that treating unit quaternions as a Riemannian manifold has huge implications for optimization, imitation learning and other robotics applications<d-cite key="7829369"></d-cite><d-cite key="noemie2020thesis"></d-cite><d-cite key="Jaquier2018GeometryawareML"></d-cite><d-cite key="Calinon2019GaussiansOR"></d-cite><d-cite key="Silvrio2017LearningTP"></d-cite>. Through numerous research works, it has been shown that the marriage of quaternions and Riemannian geometry enables us to tackle complex problems with newfound precision and insight.</p> <p>May your explorations be filled with wonder and revelation.</p>]]></content><author><name>Akshay L Chandra</name></author><summary type="html"><![CDATA[Exploring the geometric effects of the quaternion rotation operator]]></summary></entry><entry><title type="html">[2/3] Towards a 3D Rotation Operator with a Quaternion Sandwich</title><link href="https://akshaychandra.com/blog/2023/quat-rot-op1/" rel="alternate" type="text/html" title="[2/3] Towards a 3D Rotation Operator with a Quaternion Sandwich"/><published>2023-10-07T00:00:00+00:00</published><updated>2023-10-07T00:00:00+00:00</updated><id>https://akshaychandra.com/blog/2023/quat-rot-op1</id><content type="html" xml:base="https://akshaychandra.com/blog/2023/quat-rot-op1/"><![CDATA[<blockquote> <p><strong>Citation Note:</strong> I have borrowed this article’s content from Jack B. Kuipers’ seminal 1999 book <d-cite key="kuipers1999quaternions"></d-cite> on quaternions.</p> </blockquote> <blockquote> <p>As an admirer of the book’s writing style, I submit that you are probably better off referring to Chapter 5 of the book. My motivation to write this regardless is twofold - to provide robotics practitioners with a one-stop-shop entry point to quaternions and challenge/improve my understanding of them. I claim no expertise in this topic but found it so fascinating that I decided to write about it.</p> </blockquote> <blockquote> <p><strong>Prerequisites:</strong> This is [2/3] article in my series on quaternions. For this article, I assume readers’ familiarity with basic quaternion algebra <d-cite key="quat-basics"></d-cite> and rotation matrices and their basic properties<d-cite key="rotmat"></d-cite><d-cite key="rotmat2d"></d-cite><d-cite key="rotmat3d"></d-cite>.</p> </blockquote> <hr/> <h2 id="agenda">Agenda</h2> <p>After going back and forth about it in my mind, I have decided to write about the quaternion rotation operator in two parts:</p> <ul> <li>one that proposes a checklist of qualities necessary to be a reasonably good \(\mathbb{R}^3\) rotation operator and introduces the necessary tools to meet the checklist (this one)</li> <li>one that discusses the geometric effects of the quaternion rotation operator (next one <d-cite key="quat-rot-op2"></d-cite>)</li> </ul> <p>At the cost of clarity, I am probably risking losing readers’ attention and I only hope to keep you interested enough to stay aboard till the end of the series.</p> <h2 id="quaternion-rotation-operator-checklist">Quaternion Rotation Operator: Checklist</h2> <p>As we know, rotation matrices are \(3 \times 3\) orthogonal matrices with determinant 1 (unimodular). In fact, one can use any \(3 \times 3\) matrix \(R\) that satisfies the orthogonality and the unimodularity<d-footnote>A matrix is unimodular if it has a determinant 1 or -1. But in this case, I am only talking about it being 1.</d-footnote> properties to represent rotations in \(\mathbb{R}^3\). To find a vector \(\vec{v}\)’s rotated image \(\vec{w}\) under \(R\), we simply do the left matrix multiplication between \(R\) and a column matrix that whose entries are components of \(\vec{v}\) i.e., \(R\vec{v}\). It helps to recollect that the image \(\vec{w}\), thanks to the unimodularity of \(R\), has the same magnitude as \(\vec{v}\). If one were to <em>invent</em> a quaternion rotation operator, say \(R_{\mathbf{q}}\) (associated with the quaternion \(\mathbf{q}\)), it should satisfy the following:</p> \[\vec{w} = R_{\mathbf{q}}(\vec{v})\] <p>And more importantly, similar to rotation matrices, the operator \(R_{\mathbf{q}}\) should somehow bring about a notion of an axis and an angle of rotation to it. Of course the quaternion operator should also be able to reproduce other properties such as sequence of rotations i.e., have an equivalent form of \(R_1R_2R_3\vec{v}\), say \(R_{\mathbf{q}_1\mathbf{q}_2\mathbf{q}_3}\) and reverse rotations (e.g. \(R_1^{-1}R_2R_3\vec{v}\)) and more.</p> <p>Perhaps we’ll worry about them later but at its core, it appears that the four fundamental desirable qualities of rotation operator \(R_{\mathbf{q}}\) are as follows:</p> <ol> <li>\(R_{\mathbf{q}}\) should be able to operate on vectors.</li> <li>\(R_{\mathbf{q}}\) should always output a vector in \(\mathbb{R}^3\).</li> <li>\(R_{\mathbf{q}}\) shouldn’t scale the vectors.</li> <li>\(R_{\mathbf{q}}\) should associate with an angle<d-footnote>Also an axis of rotation but we look at that in my next article.</d-footnote> unique to \(\mathbf{q}\).</li> </ol> <p>By the end of this article, we will see that this checklist is indeed fulfilled with quaternions albeit with some upgrades.</p> <h2 id="pure-quaternions">Pure Quaternions</h2> <p>How can quaternions which are in \(\mathbb{R}^4\) operate on vectors in \(\mathbb{R}^3\)? Thanks to the Scalar + Vector model we discussed in <d-cite key="quat-basics"></d-cite>, a vector can be interpreted as a <em>pure quaternion</em><d-footnote>One might argue that real numbers are just scalar parts of quaternions. And why shouldn't they?</d-footnote> i.e., \(\mathbf{v} = 0 + \vec{v}\). So \(Q_0\), the set of all pure quaternions, is a subset of \(Q\), the set of all quaternions. To that end, we can easily verify that:</p> <ul> <li>Quaternion addition between any two pure quaternions</li> <li>Quaternion multiplication between any two pure quaternions</li> <li>Quaternion multiplication between a scalar and a pure quaternion</li> </ul> <p>provide a <em>one-to-one correspondence</em> between \(\mathbb{R}^3\) and \(Q_0\). This is great and goes toward items 1 and 2 on our checklist.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/pure_quat-480.webp 480w,/assets/img/blog/pure_quat-800.webp 800w,/assets/img/blog/pure_quat-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/pure_quat.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Source: Jack B Kuipers. Quaternions and Rotation Sequences (1999)</figcaption> </figure> <p>However, multiplication (See Eq. \((1)\) from <d-cite key="quat-basics"></d-cite> for clarity) between a general and a pure quaternion doesn’t <em>always</em> give us the same desirable one-to-one mapping. Still, it exists and is as follows:</p> \[\begin{aligned} \mathbf{q} \star \mathbf{v} &amp;= (q_0 + \vec{q}) \star (0 + \vec{v}) \\ &amp;= q_0 \cdot 0 - \vec{q} \cdot \vec{v} + 0 \cdot \vec{q} + q_0\vec{v} + \vec{q} \times \vec{v}\\ &amp;= -\vec{q} \cdot \vec{v} + q_0\vec{v} + \vec{q} \times \vec{v} \hspace{10cm} \text{(1)} \end{aligned}\] <p>It is now clear that quaternion multiplication allows us to operate on vectors, as one should expect if one wants to define an \(\mathbb{R}^3\) rotation operator based on quaternions.</p> <blockquote> <p><strong>:heavy_check_mark: Item 1 in the list is checked. Quaternions can indeed operate on vectors, a.k.a pure quaternions, in a rather straightforward way.</strong></p> </blockquote> <h2 id="quaternion-sandwich-product">Quaternion Sandwich Product</h2> <p>For quaternions to operate on vectors in \(\mathbb{R}^3\), it would have helped a lot in favour of item 2 in our list if their multiplication led to a one-to-one correspondence between \(\mathbb{R}^3\) and \(Q_0\). However, we see in Eq. \(\text{(1)}\) that the <em>double</em> product still has a scalar part. This is why the <em>double</em> products \(\mathbf{q} \star \mathbf{v}\) and \(\mathbf{v} \star \mathbf{q}\)<d-footnote>The commutation does not change the scalar part.</d-footnote> do not have a place in \(R_{\mathbf{q}}\). This suggests that the quaternion operator \(R_{\mathbf{q}}\) must have a <em>triple</em> or even higher order quaternion multiplication in it.</p> <p>As one should, let us see if a <em>triple</em> product gives us what we want and what we want is to be able to stay in \(\mathbb{R}^3\) after the multiplication. Consider two general quaternions \(\mathbf{p}=p_0 + \vec{p}\) and \(\mathbf{q} = q_0 + \vec{q}\) and a pure quaternion \(\mathbf{v} = 0 + \vec{v}\). There are six possible products involving these three quaternions:</p> \[\begin{aligned} &amp;\mathbf{p} \star \mathbf{q} \star \mathbf{v} \quad \mathbf{q} \star \mathbf{v} \star \mathbf{p} \quad \mathbf{v} \star \mathbf{p} \star \mathbf{q} \\ &amp;\mathbf{q} \star \mathbf{p} \star \mathbf{v} \quad \mathbf{p} \star \mathbf{v} \star \mathbf{q} \quad \mathbf{v} \star \mathbf{q} \star \mathbf{p} \end{aligned}\] <p>On examination, we see that all products where \(\mathbf{p}\) and \(\mathbf{q}\) are together lead to the same problem we discussed earlier. Their product, regardless of the order, would return another general quaternion, making them <em>double</em> products. Our last hope seems to be in the two leftover <em>triple</em> products <d-footnote>Although, I suspect the section's title must have given away the plot already.</d-footnote></p> \[\mathbf{p} \star \mathbf{v} \star \mathbf{q} \quad \quad \mathbf{q} \star \mathbf{v} \star \mathbf{p}\] <p>Despite the uninteresting exercise, lets expand the <em>triple</em> products, say \(\mathbf{p} \star \mathbf{v} \star \mathbf{q}\).</p> \[\begin{aligned} \mathbf{p} \star \mathbf{v} \star \mathbf{q} &amp;= (\mathbf{p} \star \mathbf{v}) \star \mathbf{q} \\ &amp;= (-\vec{p}\cdot\vec{v} + p_0\vec{v} + \vec{p} \times \vec{v}) \star \mathbf{q} \\ &amp;= - q_0 \vec{p}\cdot\vec{v} - (p_0\vec{v} + \vec{p} \times \vec{v}) \cdot \vec{q} + (-\vec{p}\cdot\vec{v})\cdot\vec{q} \\ &amp;\quad + q_0(p_0\vec{v} + \vec{p} \times \vec{v}) + (p_0\vec{v} + \vec{p} \times \vec{v}) \times \vec{q} \\ &amp;= - q_0 (\vec{p}\cdot\vec{v}) - p_0(\vec{v} \cdot \vec{q}) - (\vec{p} \times \vec{v}) \cdot \vec{q} \\ &amp; \quad - (\vec{p}\cdot\vec{v})\cdot\vec{q} + q_0(p_0\vec{v} + \vec{p} \times \vec{v}) \\ &amp; \quad + (p_0\vec{v} + \vec{p} \times \vec{v}) \times \vec{q} \end{aligned}\] <p>Separating out the scalar part from above, we have:</p> \[- q_0 (\vec{p}\cdot\vec{v}) - p_0(\vec{v} \cdot \vec{q}) - (\vec{p} \times \vec{v}) \cdot \vec{q}\] <p>We may rewrite this with a little bit of vector algebra trickery as:</p> \[- q_0 (\vec{p}\cdot\vec{v}) - p_0(\vec{v} \cdot \vec{q}) + (\vec{p} \times \vec{q}) \cdot \vec{v}\] <p>Recall that if this <em>triple</em> product were to be inside \(R_{\mathbf{q}}\), it should output a pure quaternion. So we have to choose \(\mathbf{p}\) and \(\mathbf{q}\) such that the scalar part goes to \(0\) for all pure quaternions. Examining the cross product term, we see that \((\vec{p} \times \vec{q}) \cdot \vec{v}\) would go to \(0\) if \(\mathbf{p}\) and \(\mathbf{q}\) are parallel to each other i.e., if \(\mathbf{p} = k\mathbf{q}\) for non-zero \(k\) since we are dealing with non-zero vectors \(\vec{p}\) and \(\vec{q}\)<d-footnote>Note that this is a fair assumption to make. We have full control over the quaternions; however, there is not much on the vector to be rotated.</d-footnote>. Substituting this back in the scalar part expression, we get</p> \[\begin{aligned} &amp;\Rightarrow - q_0 (k\vec{q}\cdot\vec{v}) - p_0(\vec{v} \cdot \vec{q}) + (k\vec{q} \times \vec{q}) \cdot \vec{v} \\ &amp;\Rightarrow - q_0k (\vec{q}\cdot\vec{v}) - p_0(\vec{q}\cdot\vec{v}) + 0 \cdot \vec{v} \\ &amp;\Rightarrow -(q_0k+p_0)(\vec{q}\cdot\vec{v}) \end{aligned}\] <p>It is easy to verify that the above expression goes to \(0\) when \(\vec{q}\) and \(\vec{v}\) are parallel to each other or if \(k=-1\) and \(p_0 = q_0\) which would simply mean that</p> \[\mathbf{p} = p_0 + \vec{p} = q_0 -\vec{q} \Rightarrow \mathbf{p} = \mathbf{q}^{\ast}\] <p>From this discussion, we obtain two <em>triple</em> quaternion products that always output a pure quaternion whenever they <em>sandwich</em> (hence the name) a pure quaternion, although it is not yet clear how they differ from each other</p> \[\mathbf{q} \star \mathbf{v} \star \mathbf{q}^{\ast} \quad \quad \mathbf{q}^{\ast} \star \mathbf{v} \star \mathbf{q}\] <p>The algebraic action of \(\mathbf{w} = \mathbf{q} \star \mathbf{v} \star \mathbf{q}^{\ast}\) is illustrated in the figure below.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/quat_sandwich-480.webp 480w,/assets/img/blog/quat_sandwich-800.webp 800w,/assets/img/blog/quat_sandwich-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/quat_sandwich.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Source: Jack B Kuipers. Quaternions and Rotation Sequences (1999)</figcaption> </figure> <p>A natural question to raise is - what geometric interpretation can we give this sandwich product? I study their geometric considerations more closely in my next article <d-cite key="quat-rot-op2"></d-cite>. But to see the geometrics, it helps to associate an angle with a quaternion. Is there some way to do that, analogous to the rotation matrices? In the later parts of this article, you will see that there is indeed a way to associate an angle with quaternions.</p> <blockquote> <p><strong>:heavy_check_mark: Item 2 in the list is checked as long as \(R_{\mathbf{q}}\) has sandwich product.</strong></p> </blockquote> <h2 id="unit-quaternions">Unit Quaternions</h2> <p>Unit quaternions i.e., \(\Vert \mathbf{q} \Vert^2 = (\mathbf{q}^{\ast} \star \mathbf{q}) = (\mathbf{q} \star \mathbf{q}^{\ast}) = 1\) are simply quaternions whose norm is 1. What is worth noting about unit quaternions is that their quaternion multiplication preserves membership in the \(\mathbf{S}^3\) space<d-footnote>A sphere in 4-dimensional space where each point represents a quaternion with magnitude 1.</d-footnote> of unit quaternions. That is, the quaternion product of two unit quaternions \(\mathbf{p}\) and \(\mathbf{q}\) i.e., \(\mathbf{p} \star \mathbf{q}\) will also be a unit quaternion and hence will still belong to the unit-sphere in \(\mathbf{S}^3\). This convenient geometric property allows us to do many cool things such as non-Euclidean calculus<d-cite key="boumal2023intromanifolds"></d-cite> with quaternions, something that could be exploited to learn geometry-aware models, say, a dynamical system on robot’s trajectory of both positions and orientations<d-cite key="7829369"></d-cite><d-cite key="noemie2020thesis"></d-cite><d-cite key="Jaquier2018GeometryawareML"></d-cite>. More importantly to our journey, it should be clear that the rotation operator \(R_{\mathbf{q}}\) should include unit quaternions and not general quaternions.</p> <p>Perhaps this is already obvious (from Eq. \((4)\) and Eq. \((5)\) of <d-cite key="quat-basics"></d-cite>), the quaternion sandwich product with unit quaternions wouldn’t change the magnitude of the pure quaternion \(\mathbf{v}\).</p> \[\begin{aligned} \Vert \mathbf{q} \star \mathbf{v} \star \mathbf{q}^{\ast} \Vert^2 &amp;= \Vert \mathbf{q} \Vert^2 \Vert \mathbf{v} \Vert^2 \Vert \mathbf{q}^{\ast} \Vert^2 \\ &amp;= \Vert \mathbf{v} \Vert^2 \end{aligned}\] <p>In fact, even for higher-order multiplication with unit quaternions, we see that the norm of the factors is preserved. Say, we have \(n\) unit quaternions \(\{\mathbf{q}_1, \mathbf{q}_2, ..., \mathbf{q}_n\}\) and a general quaternion \(\mathbf{p}\). The squared norm of their products in any order yields the same, as follows:</p> \[\begin{aligned} \Vert \mathbf{q}_1 \star ... \star \mathbf{p} \star ... \star \mathbf{q}_n \Vert^2 &amp;= \Vert \mathbf{p} \star \mathbf{q}_1 \star ... \star \mathbf{q}_n \Vert^2 \\ &amp;= \Vert \mathbf{q}_1 \star ... \star \mathbf{q}_n \star \mathbf{p} \Vert^2 \\ &amp;= \Vert \mathbf{p} \Vert^2 \end{aligned}\] <blockquote> <p><strong>:heavy_check_mark: Item 3 in the list is checked as long as the \(\mathbf{q}\) in \(R_{\mathbf{q}}\) is a unit quaternion.</strong></p> </blockquote> <h2 id="polar-form">Polar Form</h2> <h3 id="optional-complex-numbers">(Optional) Complex Numbers</h3> <p>Complex numbers<d-footnote>I bring complex numbers into the discussion for familiarity and easy visualisations. If this is obvious to you, please skip to the next subsection.</d-footnote> have an intuitive alternate form of representation to them. A complex number \(z = a + ib\) can be interpreted as a 2D vector on a complex plane where the horizontal axis is the real axis and the vertical axis is the imaginary axis, as shown in the figure below. A natural consequence of this is the polar or trigonometric form where \(z = a + ib\) can be represented with its polar pair \((r, \theta)\) such that \(r = \sqrt{a^2 + b^2}\) (norm) and \(\theta = \arctan (\frac{b}{a})\) (angle between complex vector and the real axes), from this it follows that \(\cos \theta = \frac{a}{r}\) and \(\sin \theta = \frac{b}{r}\).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/complex_plane-480.webp 480w,/assets/img/blog/complex_plane-800.webp 800w,/assets/img/blog/complex_plane-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/complex_plane.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Now, we see that the following holds:</p> \[\begin{aligned} z &amp;= a + ib \\ &amp;= r \cos \theta + i (r \sin \theta) \\ &amp;= r (\cos \theta + i \sin \theta) \end{aligned}\] <p>Consequently, one can obtain the complex conjugate by simply replacing \(\theta\) with \(-\theta\), i.e.,</p> \[\begin{aligned} z^{\ast} &amp;= r (\cos (-\theta) + i \sin (-\theta)) \\ &amp;= r(\cos \theta - i \sin \theta) \end{aligned}\] <p>It helps to know that one can extend this to quaternions and write them in polar form just as well.</p> <h3 id="optional-a-special-property-of-complex-product">(Optional) A Special Property of Complex Product</h3> <p>The complex polar form allows us to spot a special property inherent to complex numbers. Consider two complex numbers:</p> \[\begin{aligned} z_1 &amp;= r_1(\cos \theta_1 + i \sin \theta_1)\\ z_2 &amp;= r_2(\cos \theta_2 + i \sin \theta_2) \end{aligned}\] <p>Their complex multiplication is as follows:</p> \[\begin{aligned} z_1z_2 &amp;= r_1(\cos \theta_1 + i \sin \theta_1) . r_2(\cos \theta_2 + i \sin \theta_2) \\ &amp;= r_1r_2(\cos \theta_1 \cos \theta_2 + i \cos \theta_1 \sin \theta_2 + i \sin \theta_1 \cos \theta_2 \\ &amp; \quad - \sin \theta_1 \sin \theta_2) \\ &amp;= r_1r_2(\cos \theta_1 \cos \theta_2 - \sin \theta_1 \sin \theta_2 \\ &amp;\quad + i (\cos \theta_1 \sin \theta_2 + \sin \theta_1 \cos \theta_2)) \\ &amp;= r_1r_2(\cos (\theta_1 + \theta_2) + i \sin (\theta_1 + \theta_2)) \end{aligned}\] <p>The geometric interpretation of the complex product is clear now. When two complex numbers are multiplied, you notice that the output complex number has an associated angle that is exactly the sum of angles associated with the multiplicands and has a magnitude equal to the product of magnitudes of the multiplicands.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/complex_product-480.webp 480w,/assets/img/blog/complex_product-800.webp 800w,/assets/img/blog/complex_product-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/complex_product.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">This is true if a3+ib3 = (a1+ib1)(a2+ib2)</figcaption> </figure> <p>We can also verify that multiplying a complex number with another complex number’s conjugate essentially subtracts or <em>cancels</em> the former’s angle by latter’s angle. All of this is quite suggestive that complex numbers can be used to represent 2D rotations (also scaling for non-unit complex numbers), which is perhaps obvious or well-known to many. However, does this extend to quaternions? Yes. No. Maybe. We hope to find out soon!</p> <h3 id="quaternions">Quaternions</h3> <p>Quaternions, particularly unit quaternions, can also be written in polar form, albeit the interpretation of the angle \(\theta\) may not be as straightforward as it is for complex numbers. We know that a unit quaternion \(\mathbf{q} = q_0 + \vec{q}\) has norm 1 i.e., \(q_0^2 + \Vert \vec{q} \Vert^2 = 1\). And that for any angle \(\theta\), we know that \(\cos^2 \theta + \sin^2 \theta = 1\) holds. So there must be an angle \(\theta\) such that</p> \[\begin{aligned} \cos^2 \theta &amp;= q_0^2 \\ \sin^2 \theta &amp;= \Vert \vec{q} \Vert^2 \end{aligned}\] <p>The angle \(\theta\) can be defined uniquely as long as it stays within \((-\pi, \pi]\). But this is it, we now have an angle (although still unclear what it represents) associated with the quaternion \(\mathbf{q}\). We can take this form further by defining a unit vector \(\vec{u}\), which represents the direction of \(\vec{q}\):</p> \[\vec{u} = \frac{\vec{q}}{\Vert \vec{q} \Vert} = \frac{\vec{q}}{\sin \theta}\] <p>Then, we may be able to write all unit quaternions in terms of the associated angle \(\theta\) and the unit vector \(\vec{u}\) as</p> \[\mathbf{q} = q_0 + \vec{q} = \cos \theta + \vec{u} \sin \theta\] <p>Note, similar to complex numbers, for a quaternion expressed in this form, substituting \(-\theta\) for \(\theta\) (whatever geometric meaning the angle \(\theta\) might have) we get the complex conjugate of \(\mathbf{q}\). Which is,</p> \[\begin{aligned} \mathbf{q}^{\ast} &amp;= \cos (-\theta) + \vec{u} \sin (-\theta) \\ &amp;= \cos \theta - \vec{u} \sin \theta \end{aligned}\] <p>It is not too difficult to verify that if we replace \(\theta\) by \(-\theta\) of \(\mathbf{q}\) in one sandwich product, we get the other one out. So by the appropriate choice of the angle \(\theta\) these operators may, in fact, represent the same geometric transformation. I discuss more of this in <d-cite key="quat-rot-op2"></d-cite></p> <h3 id="a-special-property-of-quaternion-product">A Special Property of Quaternion Product</h3> <p>I hope you will have figured out where I am going with this by now. Consider two unit quaternions:</p> \[\begin{aligned} \mathbf{q}_1 &amp;= \cos \theta_1 + \vec{u} \sin \theta_1\\ \mathbf{q}_2 &amp;= \cos \theta_2 + \vec{u} \sin \theta_2 \end{aligned}\] <p>The quaternion product of these two (see \((1)\) in <d-cite key="quat-basics"></d-cite> for clarity) gives</p> \[\begin{aligned} \mathbf{q}_1 \star \mathbf{q}_2 &amp;= (\cos \theta_1 + \vec{u} \sin \theta_1)(\cos \theta_2 + \vec{u} \sin \theta_2) \\ &amp;= \cos \theta_1 \cos \theta_2 - (\vec{u} \sin \theta_1) \cdot (\vec{u} \sin \theta_2) \\ &amp; \quad + \cos \theta_1 (\vec{u} \sin \theta_2) + \cos \theta_2 (\vec{u} \sin \theta_1) + \vec{u} \sin \theta_1 \times \vec{u} \sin \theta_2 \\ &amp;= \cos \theta_1 \cos \theta_2 - \sin \theta_1 \sin \theta_2 \\ &amp; \quad + \vec{u} (\cos \theta_1 \sin \theta_2 + \sin \theta_1 \cos \theta_2)\\ &amp;= \cos (\theta_1 + \theta_2) + \vec{u} \sin (\theta_1 + \theta_2) \end{aligned}\] <p>Once again, very similar to complex numbers, this is an interesting result and has an important geometric implication. It says if we multiply two unit quaternions \(\mathbf{q}_1\) and \(\mathbf{q}_2\), each having the same unit vector \(\vec{u}\) in them, then the product is also a unit quaternion having this same unit vector \(\vec{u}\). And, associated with it is an angle that is exactly the sum of angles associated with \(\mathbf{q}_1\) and \(\mathbf{q}_2\). If, in fact, the quaternion rotation operator represents rotation, this property suggests that there is a possibility of sequencing rotations with different \(\mathbf{q}\)s, a property enjoyed by the rotation matrices.</p> <blockquote> <p><strong>:heavy_check_mark: Item 4 in the list is checked as we showed that it is possible to associate an angle \(\theta\) with unit quaternions.</strong></p> </blockquote> <h2 id="conclusion">Conclusion</h2> <p>We looked at some quaternion tricks, upgrades and forms that allow us to go from a 4-tuple vector with seemingly arbitrary product rules to a 3D rotation operator. We defined a checklist at the beginning and I would like to think that I convinced you that quaternions indeed meet all of them without room for doubt<d-footnote>I would love to answer or just ponder your questions, if any. Please feel free to write them in the comments below.</d-footnote>. Given a 3D vector as a pure quaternion \(\mathbf{v}\) and a unit quaternion \(\mathbf{q}\), we have seen considerable evidence that the quaternion rotation operator \(R_{\mathbf{q}}\) should have the form</p> \[R_{\mathbf{q}}(\mathbf{v}) = \mathbf{q} \star \mathbf{v} \star \mathbf{q}^{\ast} \quad \text{or} \quad \mathbf{q}^{\ast} \star \mathbf{v} \star \mathbf{q}\] <p>and that it is in some way related to rotations in \(\mathbb{R}^3\). However, I accept that there is still a lot to be discussed and investigated, especially the geometric effects of the sandwich product when applied to an arbitrary \(\mathbb{R}^3\) vector. I wrote about exactly this in the next article of this series <d-cite key="quat-rot-op2"></d-cite>. There we take the sandwich product to a couple of field tests and reverse engineer the output vector with some convenient visualisations.</p>]]></content><author><name>Akshay L Chandra</name></author><summary type="html"><![CDATA[All the nuts and bolts needed to go from quaternions to a quaternion rotation operator]]></summary></entry><entry><title type="html">[1/3] Quaternions: Basic Algebra</title><link href="https://akshaychandra.com/blog/2023/quaternion-basics/" rel="alternate" type="text/html" title="[1/3] Quaternions: Basic Algebra"/><published>2023-09-23T00:00:00+00:00</published><updated>2023-09-23T00:00:00+00:00</updated><id>https://akshaychandra.com/blog/2023/quaternion-basics</id><content type="html" xml:base="https://akshaychandra.com/blog/2023/quaternion-basics/"><![CDATA[<blockquote> <p><strong>Citation Note:</strong> For this article, I have borrowed many things, sometimes “as is”, from:</p> </blockquote> <blockquote> <ul> <li>Prof. Jack B. Kuipers’ seminal 1999 book <d-cite key="kuipers1999quaternions"></d-cite></li> <li>Prof. Hans-Peter Schröcker’s talk<d-cite key="schroecker2022iros"></d-cite> at IROS 2022</li> <li>Prof. Andrew Hanson’s book on quaternions<d-cite key="visquat"></d-cite></li> <li>Section I of Keith Conrad’s notes<d-cite key="conrad-quat-algebras"></d-cite>.</li> </ul> </blockquote> <blockquote> <p>This article merely reproduces their work, perhaps put together concisely in one place. My motivation to write this is twofold - to provide robotics practitioners a one-stop-shop entry point to quaternions and challenge/improve my understanding of them. I claim no expertise in this topic but found it so fascinating that I decided to write about it.</p> </blockquote> <blockquote> <p><strong>Prerequisites:</strong> This is [1/3] article in my series on quaternions. For this article, I assume no familiarity with quaternions, to the point that some parts may come across as pedantic. I do not, however, talk about representing 3D rotations via quaternions in this one, I leave that to my next article<d-cite key="quat-rot-op1"></d-cite>. My goal here is only to ensure readers get comfortable with the idea of quaternion addition, multiplication, conjugate, and norm.</p> </blockquote> <hr/> <h2 id="motivation">Motivation</h2> <p>Quaternions can efficiently represent rotations in 3D Euclidean space. Alternatively, one can turn to Euler angles<d-cite key="eulerangles"></d-cite> or to \(3 \times 3\) orthogonal matrices with determinant \(1\) i.e., rotation matrices<d-cite key="rotmat"></d-cite><d-cite key="rotmat2d"></d-cite><d-cite key="rotmat3d"></d-cite>. While rotation matrices are great in their own right, for their nine elements, they have only three degrees of freedom (redundant information) and lack geometric interpretation in their natural form<d-footnote>Well, determining rotation axis and angle need a few steps of calculations.</d-footnote>. On the other hand, a quaternion is a 4-tuple that represents 3D rotations but with a more concise form with <em>arguably</em> better geometric interpretations. It elegantly sidesteps the Gimbal Lock and ambiguity problems of Euler angles<d-cite key="visquat"></d-cite><d-cite key="eulerproblems"></d-cite><d-cite key="eulerproblems2"></d-cite> and numerical error accumulation problems of rotation matrices. Quaternions also provide a natural way of interpolating between orientations.</p> <p>To that end, I refer the readers to Chapter 2 of Prof. Andrew Hanson’s book “Visualizing Quaternions”<d-cite key="visquat"></d-cite> where he rigorously discusses how both NASA astronauts and Hollywood film directors may prefer quaternions over other representations.</p> <h2 id="history">History</h2> <p>Quaternions were introduced by W. R. Hamilton in 1843<d-cite key="hamilton1844quaternions"></d-cite>. The complex number we learn in highschool is a sum \(a+ib\) with \(a, b \in \mathbb{R}\) and \(i^2 = -1\). Addition and multiplication rules are given by</p> \[\begin{aligned} (a + ib) + (c + id) &amp; = (a + b) + (b + d)i \\ (a + ib)(c + id) &amp; = (ac - bd) + (ad + bc)i \end{aligned}\] <p>Hamilton avoided explaining what \(i\) is by declaring \(a+ib\) as ordered pairs \((a,b) \in \mathbb{R}^2\) with the following rules</p> \[\begin{aligned} (a, b) + (c, d) &amp; = (a + c, b + d) \\ (a, b)(c, d) &amp; = (ac - bd)(ad + bc) \\ (a, b) + (0, 0) &amp; = (a, b) \quad \text{(Additive identity)} \\ (a, b)(1, 0) &amp; = (a, b) \quad \text{(Multiplicative identity)} \end{aligned}\] <p>So \((a,b) = (a,0) + (0,b) = a(1,0) + b(0,1)\) is essentially \(a+ib\) if we define \(i\) as \((0, 1)\). While trying to extend this to three dimensions and find triples \((a, b, c)\), he instead discovered a way to multiply in four dimensions at the cost of abandoning commutativity of multiplcation<d-cite key="conrad-quat-algebras"></d-cite>. Legend has it that the idea to add the fourth dimension struck him while walking with his wife Helen at the Royal Irish Academy, and that he noted down the quaternion equations as they passed the Broom Bridge<d-cite key="broom"></d-cite> of the Royal Canal. A stone plaque at the exact location carved with the following equations was later commemorated:</p> \[i^2 = j^2 = k^2 = ijk = -1\] <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/William_Rowan_Hamilton_Plaque-480.webp 480w,/assets/img/blog/William_Rowan_Hamilton_Plaque-800.webp 800w,/assets/img/blog/William_Rowan_Hamilton_Plaque-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/William_Rowan_Hamilton_Plaque.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Source: Wikipedia</figcaption> </figure> <p>If mathematics and its history interests you, I refer you to this YouTube video by “Kathy Loves Physics and History”<d-cite key="kathy-quat-history"></d-cite>. In a subsequent video, she explains how the discovery of quaternions (with Maxwell’s equations) ultimately led to Vector Analysis<d-cite key="kathy-quat-history2"></d-cite>.</p> <h2 id="definition">Definition</h2> <p>The quaternions are</p> \[\mathbb{H} = \{a + bi + cj + dk: a, b, c, d \in \mathbb{R}\},\] <p>where the following rules are imposed:</p> <ul> <li> \[i^2 = j^2 = k^2 = -1 \hspace{50cm}\] </li> <li> \[ij=k, ji=-k, jk=i, kj=-i, ki=j, ki=j, ik=-j \hspace{50cm}\] </li> <li>every \(a \in \mathbb{R}\) commutes with \(i, j, k\)</li> </ul> <p>One could always look at the circle below to remember the multiplicative rules of \(i, j, k\). Products following the below order get a plus sign, otherwise a minus sign, \(e.g., ij = k\) and \(ji = -k\).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/ijk-480.webp 480w,/assets/img/blog/ijk-800.webp 800w,/assets/img/blog/ijk-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/ijk.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Source: Keith Conrad</figcaption> </figure> <h3 id="quick-comparison-with-complex-numbers">Quick Comparison with Complex Numbers</h3> <table> <tbody> <tr> <td>Complex Numbers \(\mathbb{C}\)</td> <td>\(c = a +bi, \quad a,b \in \mathbb{R}, \quad i^2=-1\)</td> </tr> <tr> <td>Complex Conjugate</td> <td>\(c^{\ast} = a -bi\)</td> </tr> <tr> <td>Real Part</td> <td>\(\text{Re}(c) = \frac{1}{2}(c + c^{\ast}) = a\)</td> </tr> <tr> <td>Imaginary Part</td> <td>\(\text{Im}(c) = \frac{1}{2}(c - c^{\ast}) = b\)</td> </tr> <tr> <td>Quadrance and Norm</td> <td>\(cc^{\ast} = a^2 + b^2, \quad \Vert c \Vert = \sqrt{cc^{\ast}}\)</td> </tr> <tr> <td>Inverse</td> <td>\(c^{-1} = \frac{c^{\ast}}{cc^{\ast}}\)</td> </tr> </tbody> </table> <p>Even though we haven’t seen how two quaternions add and multiply in detail, the following table summarizes most of theis article in a concise way.</p> <table> <tbody> <tr> <td>Quaternions \(\mathbb{H}\)</td> <td>\(\mathbf{q} = q_0 + q_1i + q_2j + q_3k, \ q_n \in \mathbb{R}, \ i^2 = j^2 = k^2 = ijk = -1\)</td> </tr> <tr> <td>Complex Conjugate</td> <td>\(\mathbf{q}^{\ast} = q_0 - q_1i - q_2j - q_3k\)</td> </tr> <tr> <td>Real Part</td> <td>\(\text{Re}(\mathbf{q}) = \frac{1}{2}(\mathbf{q} + \mathbf{q}^{\ast}) = q_0\)</td> </tr> <tr> <td>Imaginary Part</td> <td>\(\text{Im}(\mathbf{q}) = \frac{1}{2}(\mathbf{q} - \mathbf{q}^{\ast}) = q_1i +q_2j + q_3k\)</td> </tr> <tr> <td>Quadrance and Norm</td> <td>\(\mathbf{q}\mathbf{q}^{\ast} = q_0^2 + q_1^2 + q_3^2 + q_4^2, \quad \Vert \mathbf{q} \Vert = \sqrt{\mathbf{q}\mathbf{q}^{\ast}}\)</td> </tr> <tr> <td>Inverse</td> <td>\(\mathbf{q}^{-1} = \frac{\mathbf{q}^{\ast}}{\mathbf{q}\mathbf{q}^{\ast}}\)</td> </tr> </tbody> </table> <h3 id="an-example-for-clarity">An Example for Clarity</h3> <p>Solve \((3i - 5j)(5k + 9i)\).</p> \[\begin{aligned} &amp; \Rightarrow 3i \times 5k + 3i \times 9i - 5j \times 5k - 5j \times 9i \\ &amp; \Rightarrow 15(ik) + 27(i^2) - 25(jk) - 45(ji) \\ &amp; \Rightarrow 15(-j) + 27(-1) - 25(i) - 45(-k) \\ &amp; \Rightarrow -27 -25i -15j + 45k \end{aligned}\] <h2 id="quaternion-models">Quaternion Models</h2> <p>There is more than one way to interpret quaternions. Some are more intuitive than others and we see three below.</p> <h3 id="four-dimensional-vectors">Four-Dimensional Vectors</h3> <p>A straightforward way of thinking about quaternions is to treat them as four-dimensional vectors.</p> \[\begin{aligned} \mathbf{p} &amp; = p_0 + p_1i + p_2j + p_3k = (p_0, p_1, p_2, p_3)^{\top} \\ \mathbf{q} &amp; = q_0 + q_1i + q_2j + q_3k = (q_0, q_1, q_2, q_3)^{\top} \end{aligned}\] <p>To avoid operator overload with the dot product, I introduce \(\star\) as the quaternion multiplication operator. Now, the quaternion multiplication between \(\mathbf{p}\) and \(\mathbf{q}\) can be written in matrix form as follows <d-footnote>See the following subsection for a full derivation of quaternion multiplication.</d-footnote></p> \[\begin{aligned} \mathbf{p} \star \mathbf{q} &amp;= \left[ \begin{matrix} p_0q_0 - p_1q_1 - p_2q_2 - p_3q_3 \\ p_0q_1 + p_1q_0 + p_2q_3 - p_3q_2 \\ p_0q_2 - p_1q_3 + p_2q_0 + p_3q_1 \\ p_0q_3 + p_1q_2 - p_2q_1 + p_3q_0 \end{matrix} \right] \\ &amp;= \left[ \begin{matrix}p_0 &amp; -p_1 &amp; -p_2 &amp; -p_3 \\ p_1 &amp; p_0 &amp; -p_3 &amp; -p_2 \\ p_2 &amp; p_3 &amp; p_0 &amp; -p_1 \\ p_3 &amp; -p_2 &amp; p_1 &amp; p_0\end{matrix} \right] \left[ \begin{matrix} q_0 \\ q_1 \\ q_2 \\ q_3 \end{matrix} \right] = \mathbf{P}. \mathbf{q} \end{aligned}\] <p>It can be convenient to represent quaternion multiplication using matrix multiplication. One can see that \(\mathbf{P}\) is an orthogonal matrix (\(\mathbf{P}^{\top} \mathbf{P} = I_4\)) in 4D Euclidean space. However, this model still lacks geometric interpretations in 3D.</p> <h3 id="two-by-two-matrices">Two-By-Two Matrices</h3> <p>Another way of thinking about quaternions is to treat them as products of simple \(2 \times 2\) matrices:</p> \[\begin{aligned} U &amp;:= \left[ \begin{matrix} 1 &amp; 0 \\ 0 &amp; 1 \end{matrix}\right], \; I := \left[ \begin{matrix} i &amp; 0 \\ 0 &amp; -i \end{matrix}\right], \\ J &amp;:= \left[ \begin{matrix} 0 &amp; 1 \\ -1 &amp; 0 \end{matrix}\right], \; K := \left[ \begin{matrix} 0 &amp; i \\ i &amp; 0 \end{matrix}\right] \end{aligned}\] \[I^2 = J^2 = K^2 = IJK = -U\] <p>Then we have</p> \[\begin{aligned} \mathbf{q} &amp; \approx Q = q_0U + q_1I + q_2J + q_3K \\ \mathbf{q^{\ast}} &amp; \approx adj(Q), \quad \mathbf{qq^{\ast}} \approx det(Q) \quad \mathbf{q}^{-1} \approx Q^{-1} \end{aligned}\] <p>As Prof. Schröcker says in his presentation<d-cite key="schroecker2022iros"></d-cite> - “When in doubt, think of matrix multiplication!”.</p> <h3 id="scalar--vector">Scalar + Vector</h3> <p>This is perhaps the most interesting model and from now on, we stick to this one. Recall from the comparisons with complex numbers, we define the real and imaginary parts of a quaternion as follows:</p> \[\begin{aligned} \text{Re}(\mathbf{q}) &amp; = \frac{1}{2}(\mathbf{q} + \mathbf{q}^{\ast}) = q_0 \quad \text{(Scalar Part)} \\ \text{Im}(\mathbf{q}) &amp; = \frac{1}{2}(\mathbf{q} - \mathbf{q}^{\ast}) = q_1i +q_2j + q_3k \quad \text{(Vector Part)} \end{aligned}\] <p>Assuming the standard orthonormal basis for \(\mathbb{R}^3\) is given by three unit vectors \(i=(1, 0, 0), j=(0, 1, 0), k=(0, 0, 1)\), quaternions can be seen as a sum of a \(q_0\) scalar and a vector \(\vec{q} = (q_1, q_2, q_3)\). Namely,</p> \[\mathbf{q} = q_0 + q_1i + q_2j + q_3k = q_0 + \vec{q}\] <p>Which makes \(\mathbb{H} = \mathbb{R} \oplus \mathbb{R}^3\). This has major geometric significance and you will soon see why. With this, it should be straightforward to derive addition and multiplication equations for two quaternions now.</p> <h2 id="quaternion-algebra">Quaternion Algebra</h2> <p>Let us derive the basic quaternion operations in Scalar + Vector form.</p> <h3 id="addition">Addition</h3> <p>Addition operation is rather straightforward from our understanding of scalar and vector additions.</p> \[\begin{aligned} \mathbf{p} + \mathbf{q} &amp; = (p_0 + q_0) + (p_1 + q_1)i + (p_2 + q_2)j + (p_3 + q_3)k \\ &amp; = (p_0 + q_0) + (\vec{p} + \vec{q}) \end{aligned}\] <h3 id="multiplication">Multiplication</h3> <p>Similar to addition, first, let us write out the multiplication of two quaternions the naive way and see if we can transform it to the Scalar + Vector form.</p> \[\begin{aligned} \mathbf{p} \star \mathbf{q} &amp;= (p_0 + p_1i + p_2j + p_3k) (q_0 + q_1i + q_2j + q_3k) \\ \\ &amp;= p_0q_0 + p_0(q_1i + q_2j + q_3k) + p_1q_0i \\ &amp;\quad + p_1i(q_1i + q_2j + q_3k) + p_2q_0j + p_2j(q_1i + q_2j + q_3k) \\ &amp;\quad + p_3q_0k + p_3k(q_1i + q_2j + q_3k) \\ \\ &amp;= p_0q_0 + p_0(q_1i + q_2j + q_3k) + p_1q_0i + p_1q_1(i^2) \\ &amp;\quad + p_1q_2(ij) + p1q_3(ik) + p_2q_0j + p_2q_1(ji) \\ &amp;\quad + p_2q_2(j^2) + p_2q_3(jk) + p_3q_0k + p_3q_1(ki) \\ &amp;\quad + p_3q_2(kj) + p_3q_3(k^2) \\ \\ &amp; = p_0q_0 + p_0(q_1i + q_2j + q_3k) + q_0(p_1i + p_2j+ p_3k) + p_1q_1(i^2) \\ &amp;\quad + p_1q_2(ij) + p_1q_3(ik) + p_2q_1(ji) + p_2q_2(j^2) \\ &amp;\quad + p_2q_3(jk) + p_3q_1(ki) + p_3q_2(kj) + p_3q_3(k^2) \\ \\ &amp;= p_0q_0 + p_0(q_1i + q_2j + q_3k) + q_0(p_1i + p_2j+ p_3k) + p_1q_1(-1) \\ &amp;\quad + p_1q_2(k) + p_1q_3(-j) + p_2q_1(-k) + p_2q_2(-1) \\ &amp;\quad + p_2q_3(i) + p_3q_1(j) + p_3q_2(-i) + p_3q_3(-1) \\ \\ &amp;= p_0q_0 + p_0\textcolor{orange}{(q_1i + q_2j + q_3k)} + q_0\textcolor{lime}{(p_1i + p_2j+ p_3k)} \\ &amp;\quad - \textcolor{cyan}{(p_1q_1+p_2q_2 +p_3q_3)} \\ &amp;\quad + \textcolor{pink}{(p_2q_3 - p_3q_2)i + (p_3q_1 - p_1q_3)j} + \textcolor{pink}{(p_1q_2 - p_2q_1)k} \hspace{5cm} \end{aligned}\] <p>Phew! Reminiscent of the Four-Dimensions model, one can see how quickly quaternion products in their naive form become cumbersome, unintuitive and inconvenient. Thankfully, the Scalar + Vector model allows us to rewrite the above equation in terms of dot and cross products as follows:</p> \[\mathbf{p} \star \mathbf{q} = p_0q_0 -\textcolor{cyan}{\vec{p} \cdot \vec{q}} + p_0\textcolor{orange}{\vec{q}} + q_0\textcolor{lime}{\vec{p}} + \textcolor{pink}{\vec{p} \times \vec{q}} \tag{1}\] <p>This is great! Finally, we reach a point where we can simply add scalars (\(p_0q_0 -\textcolor{cyan}{\vec{p} \cdot \vec{q}}\)) and 3D vectors (\(p_0\textcolor{orange}{\vec{q}} + q_0\textcolor{lime}{\vec{p}} + \textcolor{pink}{\vec{p} \times \vec{q}}\)) to compute quaternion multiplication. Eq. \(\text{(1)}\) allows us to make the following observations:</p> <ul> <li>The source of non-commutativity of quaternion multiplication is now clear, i.e., \(\vec{p} \times \vec{q} = - \vec{q} \times \vec{p}\)</li> <li>Two non-zero quaternions can commute only when their vector parts are linearly dependent (parallel) i.e., \(\mathbf{p} \star \mathbf{q} = \mathbf{q} \star \mathbf{p} \Leftrightarrow \vec{p} \times \vec{q} = 0 \hspace{50cm}\)</li> <li>Only scalars commute with all quaternions, i.e., \(c \star \mathbf{q} = cq_0 + c\vec{q} = c \mathbf{q} = \mathbf{q} \star c\).</li> <li>Since quaternion multiplication is just a combination of scalar-vector, dot and cross products in \(\mathbb{R}^3\) (Euclidean space), it <em>must</em> have some geometric significance, it <em>must</em> describe something independent of the values of \(\mathbf{p}\) and \(\mathbf{q}\). I discuss this in detail in <d-cite key="quat-rot-op2"></d-cite>.</li> </ul> <h3 id="complex-conjugate">Complex Conjugate</h3> <p>The <em>conjugate</em> of a quaternion \(\mathbf{q}\) is denoted by \(\mathbf{q^{\ast}}\) and defined as</p> \[\mathbf{q^{\ast}} = q_0 - q_1i - q_2j - q_3k = q_0 - \vec{q} \tag{2}\] <p>From the definition, it follows that:</p> \[\begin{aligned} (\mathbf{q^{\ast}})^{\ast} &amp; = q_0 - (-\vec{q}) = \mathbf{q} \\ \mathbf{q} + \mathbf{q^{\ast}} &amp; = 2q_0 \\ \mathbf{q} - \mathbf{q^{\ast}} &amp; = 2\vec{q} \\ \mathbf{q^{\ast}} \star \mathbf{q} &amp; = (q_0 - \vec{q}) \star (q_0 + \vec{q}) \\ &amp; = q_0q_0 - (-\vec{q}) \cdot \vec{q} + q_0\vec{q} \\ &amp; \quad + (-\vec{q})q_0 + (-\vec{q}) \times \vec{q} \quad \text{(from Eq. (1))} \\ &amp; = q_0^2 + \vec{q} \cdot \vec{q} \\ &amp; = q_0^2 + q_1^2 + q_2^2 + q_3^2 \quad \text{(Quadrance)} \\ &amp; = \mathbf{q} \star \mathbf{q^{\ast}} \quad \text{(Commutative)} \\ \end{aligned}\] <p>We can also easily derive the conjugate of a quaternion multiplication.</p> \[\begin{aligned} (\mathbf{p} \star \mathbf{q})^{\ast} &amp; = (p_0q_0 -\vec{p} \cdot \vec{q} + p_0\vec{q} + q_0\vec{p} + \vec{p} \times \vec{q})^{\ast} \quad \text{(from Eq. (1))}\\ &amp; = (p_0q_0 -\vec{p} \cdot \vec{q} - p_0\vec{q} - q_0\vec{p} - \vec{p} \times \vec{q}) \quad \text{(from Eq. (2))}\\ &amp; = (p_0q_0 -(-\vec{p}) \cdot (-\vec{q}) + p_0(-\vec{q}) \\ &amp; \quad + q_0(-\vec{p}) - (-\vec{p}) \times (-\vec{q})) \quad \text{(Since } a \times b = (-a \times -b)\text{)}\\ &amp; = (p_0q_0 -(-\vec{p}) \cdot (-\vec{q}) + p_0(-\vec{q}) \\ &amp; \quad + q_0(-\vec{p}) + (-\vec{q}) \times (-\vec{p})) \quad \text{(Since } a \times b = - (b \times a)\text{)}\\ &amp; = \mathbf{q}^{\ast} \star \mathbf{p}^{\ast} \hspace{10cm} \text{(3)} \end{aligned}\] <p>With Eq. \(\text{(3)}\), we can now easily find the conjugate of quaternion multiplications of more than two quaternions and you see that the above form extends. Given four quaternions \(\mathbf{q}_1, \mathbf{q}_2, \mathbf{q}_3\) and \(\mathbf{q}_4\), we have</p> \[\begin{aligned} (\mathbf{q}_1 \star \mathbf{q}_2 \star \mathbf{q}_3)^{\ast} &amp;= ((\mathbf{q}_1 \star \mathbf{q}_2) \star \mathbf{q}_3)^{\ast}\\ &amp;= \mathbf{q}_3^{\ast} \star (\mathbf{q}_1 \star \mathbf{q}_2)^{\ast} \quad \text{(from Eq. (3))}\\ &amp;= \mathbf{q}_3^{\ast} \star \mathbf{q}_2^{\ast} \star \mathbf{q}_1^{\ast} \\ (\mathbf{q}_1 \star \mathbf{q}_2 \star \mathbf{q}_3 \star \mathbf{q}_4)^{\ast} &amp;= ((\mathbf{q}_1 \star \mathbf{q}_2) \star (\mathbf{q}_3 \star \mathbf{q}_4))^{\ast} \\ &amp;= (\mathbf{q}_3 \star \mathbf{q}_4)^{\ast} \star (\mathbf{q}_1 \star \mathbf{q}_2) ^{\ast} \\ &amp;= \mathbf{q}_4^{\ast} \star \mathbf{q}_3^{\ast} \star \mathbf{q}_2^{\ast} \star \mathbf{q}_1^{\ast} \\ \end{aligned}\] <h3 id="norm">Norm</h3> <p>The squared <em>norm</em> of a quaternion \(\mathbf{q}\) is simply its quadrance</p> \[\begin{aligned} \Vert \mathbf{q} \Vert^2 &amp;= q_0^2 + q_1^2 + q_2^2 + q_3^2 \\ &amp;= \mathbf{q^{\ast}} \star \mathbf{q} = \mathbf{q} \star \mathbf{q^{\ast}} \\ &amp;= q_0^2 + (\vec{q} \cdot \vec{q}) \end{aligned}\] <p>Deriving an equation for the squared <em>norm</em> of the quaternion product is easier with quadrance.</p> \[\begin{aligned} \Vert \mathbf{p} \star \mathbf{q} \Vert^2 &amp;= (\mathbf{p} \star \mathbf{q}) \star (\mathbf{p} \star \mathbf{q})^{\ast} \\ &amp;= \mathbf{p} \star \mathbf{q} \star \mathbf{q}^{\ast} \star \mathbf{p}^{\ast} \quad \text{(from Eq. (3))}\\ &amp;= \mathbf{p} \star \Vert \mathbf{q} \Vert^2 \star \mathbf{p}^{\ast} \\ &amp;= \Vert \mathbf{q} \Vert^2 \mathbf{p} \star \mathbf{p}^{\ast} \quad \text{(Scalars commute with quaternions)} \\ &amp;= \Vert \mathbf{q} \Vert^2 \Vert \mathbf{p} \Vert^2 \hspace{12cm} \text{(4)}\\ \end{aligned}\] <p>This relationship extends to higher-order quaternion multiplication as well. Given \(n\) quaternions \(\{\mathbf{q}_1, \mathbf{q}_2, ... \mathbf{q}_n\}\), one could easily derive the following</p> \[\begin{aligned} \Vert \mathbf{q}_1 \star \mathbf{q}_2 \star \mathbf{q}_3 \Vert^2 &amp;= \Vert \mathbf{q}_1 \Vert^2 \Vert \mathbf{q}_2 \Vert^2 \Vert \mathbf{q}_3 \Vert^2 \\ \Vert \mathbf{q}_1 \star \mathbf{q}_2 \star \mathbf{q}_3 \star \mathbf{q}_4 \Vert^2 &amp;= \Vert \mathbf{q}_1 \Vert^2 \Vert \mathbf{q}_2 \Vert^2 \Vert \mathbf{q}_3 \Vert^2 \Vert \mathbf{q}_4 \Vert^2 \\ \Vert \mathbf{q}_1 \star ... \star \mathbf{q}_n \Vert^2 &amp;= \Vert \mathbf{q}_1 \Vert^2 ... \Vert \mathbf{q}_n \Vert^2 \hspace{8.5cm} \text{(5)} \end{aligned}\] <h3 id="inverse">Inverse</h3> <p>The <em>inverse</em> of a quaternion \(\mathbf{q}\) is defined as</p> \[\mathbf{q}^{-1} = \frac{\mathbf{q^{\ast}}}{\mathbf{q^{\ast}} \star \mathbf{q}} \quad \Rightarrow \mathbf{q}^{-1} \star \mathbf{q} = 1\] <h2 id="conclusion">Conclusion</h2> <p>In this article, we’ve delved into the seemingly peculiar realm of quaternion algebra. We started by introducing quaternions as a four-dimensional extension of complex numbers, consisting of a real part and three imaginary components. We looked into some commonly used quaternion models, and then explored the <em>Scalar + Vector</em> model’s arithmetic operations and properties, including addition, scalar and quaternion multiplication, complex conjugate, norm and inverse and discussed the source of non-commutativity of their multiplication. In my next article <d-cite key="quat-rot-op1"></d-cite>, we’ll take this understanding a step further by exploring how quaternions can be <em>easily</em> extended to form a rotation operator in \(\mathbb{R}^3\).</p>]]></content><author><name>Akshay L Chandra</name></author><summary type="html"><![CDATA[A brief introduction to quaternions and their basic algebra]]></summary></entry><entry><title type="html">Learning Parameters Part 5: AdaGrad, RMSProp, and Adam</title><link href="https://akshaychandra.com/blog/2019/learning-parameters-part-5-adagrad-rmsprop-and-adam/" rel="alternate" type="text/html" title="Learning Parameters Part 5: AdaGrad, RMSProp, and Adam"/><published>2019-09-27T04:38:57+00:00</published><updated>2019-09-27T04:38:57+00:00</updated><id>https://akshaychandra.com/blog/2019/learning-parameters-part-5-adagrad-rmsprop-and-adam</id><content type="html" xml:base="https://akshaychandra.com/blog/2019/learning-parameters-part-5-adagrad-rmsprop-and-adam/"><![CDATA[<h4><a href="https://medium.com/tag/learning-parameters/latest">Learning Parameters</a></h4> <h3>Learning Parameters, Part 5: AdaGrad, RMSProp, and Adam</h3> <h4>Let’s look at gradient descent with an adaptive learning rate.</h4> <p>In <a href="https://towardsdatascience.com/learning-parameters-part-4-6a18d1d3000b">part 4</a>, we looked at some heuristics that can help us tune the learning rate and momentum better. In this final article of the <a href="https://medium.com/tag/learning-parameters/latest">series</a>, let us look at a more <em>principled</em> way of adjusting the learning rate and give the learning rate a chance to adapt.</p> <blockquote>Citation Note: Most of the content and figures in this blog are directly taken from Lecture 5 of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html">CS7015: Deep Learning</a> course offered by <a href="https://www.cse.iitm.ac.in/~miteshk/">Prof. Mitesh Khapra</a> at IIT-Madras.</blockquote> <h4>Motivation for Adaptive Learning Rate</h4> <p>Consider the following simple perceptron network with sigmoid activation.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/607/1*CRj9U6_LBVMFEaceunB0CA.png"/></figure> <p>It should be easy to see that given a single point (<strong>x</strong>, <em>y</em>), gradients of <strong>w </strong>would be the following:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/625/1*8t9xxheID3mR741SMGBxwA.png"/><figcaption>See <a href="https://towardsdatascience.com/learning-parameters-part-1-eb3e8bb9ffbb">Part-1</a> if this is unclear.</figcaption></figure> <p>Gradient of <strong><em>f(x)</em></strong><em> </em>w.r.t to a particular weight is clearly dependent on its corresponding input. If there are <em>n</em> points, we can just sum the gradients over all the <em>n</em> points to get the total gradient. This news is neither new nor special. But what would happen if the feature <strong><em>x2 </em></strong>is very sparse (i.e., if its value is 0 for most inputs)? It is fair to assume that ∇<strong><em>w2</em></strong> will be 0 for most inputs (see formula) and hence <strong><em>w2</em></strong> will not get enough updates.</p> <p>Why should that bother us though? It is important to note that if at all <strong><em>x2</em></strong> is both sparse as well as important, we would want to take the updates to <strong><em>w2</em> </strong>seriously. To make sure updates happen even when a particular input is sparse, can we have a different learning rate for each parameter which takes care of the frequency of the features? We sure can. I mean that is the whole point of this article.</p> <h3><strong>AdaGrad — Adaptive Gradient Algorithm</strong></h3> <h4>Intuition</h4> <p>Decay the learning rate for parameters in proportion to their update history (more updates means more decay).</p> <h4>Update Rule for AdaGrad</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/327/1*KN7IkA5J5ZpQ6LjLrtmZwA.png"/></figure> <p>It is clear from the update rule that history of the gradient is accumulated in <strong><em>v</em></strong>. The smaller the gradient accumulated, the smaller the <strong><em>v</em></strong> value will be, leading to a bigger learning rate (because <strong><em>v</em></strong> divides <em>η</em>).</p> <h4>Python Code for AdaGrad</h4> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/942b7c5162578113b707cb997c478c13/href">https://medium.com/media/942b7c5162578113b707cb997c478c13/href</a></iframe> <h4>AdaGrad in Action</h4> <p>To see AdaGrad in action, we need to first create some data where one of the features is sparse. How would we do this to the toy network we used across all parts of the Learning Parameters series? Well, our network has just two parameters (<strong><em>w</em></strong> and <strong><em>b</em></strong>, see <em>Motivation </em>in <a href="https://towardsdatascience.com/learning-parameters-part-1-eb3e8bb9ffbb">part-1</a>). Of these, the input/feature corresponding to b is always on, so we can’t really make it sparse. So the only option is to make x sparse. Which is why we created 100 random <em>(x,y)</em> pairs and then roughly 80% of these pairs we set <em>x</em> to 0, making the feature for <strong><em>w</em></strong> sparse.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/599/1*g8b6r_qAQC4NiJ2h_UFsuw.png"/><figcaption>Vanilla GD(black), momentum (red), NAG (blue)</figcaption></figure> <p>Before we actually look at AdaGrad in action, please look at the other 3 optimizers above - vanilla GD(black), momentum (red), NAG (blue). There is something interesting that these 3 optimizers are doing for this dataset. Can you spot it? Feel free to pause and ponder. <strong>Answer:</strong> Initially, all three algorithms are moving mainly along the vertical (<strong><em>b</em></strong>) axis and there is very little movement along the horizontal (<strong><em>w</em></strong>) axis. Why? Because in our data, the feature corresponding to <strong><em>w</em></strong> is sparse and hence <strong><em>w</em></strong> undergoes very few updates. On the other hand, <strong><em>b</em></strong> is very dense and undergoes many updates. Such sparsity is very common in large neural networks containing 1000s of input features and hence we need to address it. Let us now look at AdaGrad in action.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/448/1*aflJY_KSjorG1YHNiz7Rnw.gif"/></figure> <p>Voila! By using a parameter specific learning rate AdaGrad ensures that despite sparsity <strong><em>w</em></strong> gets a higher learning rate and hence larger updates. Furthermore, it also ensures that if <strong><em>b</em></strong> undergoes a lot of updates, its effective learning rate decreases because of the growing denominator. In practice, this does not work so well if we remove the square root from the denominator (something to ponder about). What’s the flipside? Over time the effective learning rate for <strong><em>b</em></strong> will decay to an extent that there will be no further updates to <strong><em>b</em></strong>. Can we avoid this? RMSProp can!</p> <h3>RMSProp — <strong>Root Mean Square Propagation</strong></h3> <h4>Intuition</h4> <p>AdaGrad decays the learning rate very aggressively (as the denominator grows). As a result, after a while, the frequent parameters will start receiving very small updates because of the decayed learning rate. To avoid this why not decay the denominator and prevent its rapid growth.</p> <h4>Update Rule for RMSProp</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/371/1*oTk6bl5ccXp9540bFv8WXg.png"/></figure> <p>Everything is very similar to AdaGrad, except now we decay the denominator as well.</p> <h4>Python Code for RMSProp</h4> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/c5df21bfe487f20a162b485a4dad3ed5/href">https://medium.com/media/c5df21bfe487f20a162b485a4dad3ed5/href</a></iframe> <h4>RMSProp in Action</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/488/1*rn3JEQkOB3Znob1Y_EHakg.gif"/><figcaption>Vanilla GD(black), momentum (red), NAG (blue), AdaGrad (magenta)</figcaption></figure> <p>What do you see? How is RMSProp different from AdaGrad? Feel free to pause and ponder. <strong>Answer:</strong> AdaGrad got stuck when it was close to convergence, it was no longer able to move in the vertical (<strong><em>b</em></strong>) direction<br/>because of the decayed learning rate. RMSProp overcomes this problem by being less aggressive on the decay.</p> <h3>Adam — <strong>Adaptive Moment Estimation</strong></h3> <h4><strong>Intuition</strong></h4> <p>Do everything that RMSProp does to solve the denominator decay problem of AdaGrad. In addition to that, use a cumulative history of gradients.</p> <h4>Update Rule for Adam</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/538/1*Qzpf8aKwdBYTgMuL69C5qw.png"/></figure> <p>and a similar set of equations for <strong><em>b</em></strong><em>_t</em>. Notice that the update rule for Adam is very similar to RMSProp, except we look at the cumulative history of gradients as well (<strong><em>m</em></strong><em>_t</em>). Note that the third step in the update rule above is bias correction. Explanation by Prof. Mitesh M Khapra on why bias correction is necessary can be found <a href="https://www.youtube.com/watch?v=-0ZMU-gnm2g">here</a>.</p> <h4>Python Code for Adam</h4> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/965d202d6fc0b9b58c4ad7514b870b90/href">https://medium.com/media/965d202d6fc0b9b58c4ad7514b870b90/href</a></iframe> <h4>Adam in Action</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/488/1*m9JMNb9z2bzFlmPfK0WGUQ.gif"/></figure> <p>Quite clearly, taking a cumulative history of gradients speeds it up. For this toy dataset, it appears to be overshooting (a little) but even then it converges way faster than the other optimizers.</p> <h3>Million Dollar Question: Which algorithm to use?</h3> <ul><li>Adam seems to be more or less the default choice now (<em>β1</em> = 0.9, <em>β2</em> = 0.999 and <em>ϵ</em> = 1e − 8 ).</li><li>Although it is supposed to be robust to initial learning rates, we have observed that for sequence generation problems <em>η</em> = 0.001, 0.0001 works best.</li><li>Having said that, many papers report that SGD with momentum (Nesterov or classical) with a simple annealing learning rate schedule also works well in practice (typically, starting with <em>η</em> = 0.001, 0.0001 for sequence generation problems).</li><li>Adam might just be the best choice overall.</li><li>Some recent work suggests that there is a problem with Adam and it will not converge in some cases.</li></ul> <h3>Conclusion</h3> <p>In this final article of the series, we looked at how gradient descent with adaptive learning rate can help speed up convergence in neural networks. Intuition, python code and visual illustration of three widely used optimizers — AdaGrad, RMSProp, and Adam are covered in this article. Adam combines the best properties of RMSProp and AdaGrad to work well even with noisy or sparse datasets.</p> <h3>Acknowledgment</h3> <p>A lot of credit goes to <a href="https://www.cse.iitm.ac.in/~miteshk/"><strong>Prof. Mitesh M Khapra</strong></a> and the TAs of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html"><strong>CS7015: Deep Learning</strong></a><strong> </strong>course by IIT Madras for such rich content and creative visualizations. I merely just compiled the provided lecture notes and lecture videos concisely.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/816/1*x0_9l2EDmWXxkqCNxKoWfA.png"/><figcaption><strong>Source:</strong> Paperspace article on RMSProp by <a href="https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/">Ayoosh Kathuria</a>.</figcaption></figure> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=65a2f3583f7d" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/towards-data-science/learning-parameters-part-5-65a2f3583f7d">Learning Parameters Part 5: AdaGrad, RMSProp, and Adam</a> was originally published in <a href="https://medium.com/towards-data-science">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Learning Parameters Part 4: Tips For Adjusting Learning Rate, Line Search</title><link href="https://akshaychandra.com/blog/2019/learning-parameters-part-4-tips-for-adjusting-learning-rate-line-search/" rel="alternate" type="text/html" title="Learning Parameters Part 4: Tips For Adjusting Learning Rate, Line Search"/><published>2019-09-27T03:37:12+00:00</published><updated>2019-09-27T03:37:12+00:00</updated><id>https://akshaychandra.com/blog/2019/learning-parameters-part-4-tips-for-adjusting-learning-rate-line-search</id><content type="html" xml:base="https://akshaychandra.com/blog/2019/learning-parameters-part-4-tips-for-adjusting-learning-rate-line-search/"><![CDATA[<h4><a href="https://medium.com/tag/learning-parameters/latest">Learning Parameters</a></h4> <h3>Learning Parameters, Part 4: Tips For Adjusting Learning Rate, Line Search</h3> <h4>Before moving on to advanced optimization algorithms let us revisit the problem of learning rate in gradient descent.</h4> <p>In <a href="https://towardsdatascience.com/learning-parameters-part-3-ee8558f65dd7">part 3</a>, we looked at stochastics and mini-batch versions of the optimizers. In this post, we will look at some commonly followed heuristics on how to tune the learning rate, etc. If you are not interested in these heuristics, feel free to skip to <a href="https://towardsdatascience.com/learning-parameters-part-5-65a2f3583f7d">part 5</a> of the <a href="https://medium.com/tag/learning-parameters/latest">Learning Parameters</a> series.</p> <blockquote>Citation Note: Most of the content and figures in this blog are directly taken from Lecture 5 of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html">CS7015: Deep Learning</a> course offered by <a href="https://www.cse.iitm.ac.in/~miteshk/">Prof. Mitesh Khapra</a> at IIT-Madras.</blockquote> <p>One could argue that we could have solved the problem of navigating gentle slopes by setting the learning rate high (i.e., blow up the small gradient by multiplying it with a large learning rate <strong><em>η</em></strong>). This seemingly trivial idea does sometimes work at gentle slopes of the error function, but it fails to work when the error surface is flat. Here’s an example:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/468/1*umP0flU2tdvAAfW_qfli_g.gif"/></figure> <p>Clearly, on the regions which have a steep slope, the already large gradient blows up further and the large learning rate sort of helps the cause but as soon as the error surface flattens, it doesn’t help a lot. It would be safe to assume that it is always good to have a learning rate which could adjust to the gradient and we will see a few such algorithms in the next post (part 5) in the Learning Parameters series.</p> <h3>Some Useful Tips</h3> <h4>Tips for Initial Learning Rate</h4> <ul><li>Tune learning rate. Try different values on a log scale: 0.0001, 0.001, 0.01, 0.1, 1.0.</li><li>Run a few epochs with each of these and figure out a learning rate which works best.</li><li>Now do a finer search around this value. For example, if the best learning rate was 0.1 then now try some values around it: 0.05, 0.2, 0.3.</li><li>Disclaimer: these are just heuristics, no clear winner strategy.</li></ul> <h4>Tips for Annealing Learning Rate</h4> <p><strong>Step Decay</strong></p> <ul><li>Halve the learning rate after every 5 epochs</li><li>Halve the learning rate after an epoch if the validation error is more than what it was at the end of the previous epoch</li></ul> <p><strong>Exponential Decay</strong></p> <ul><li><em>η = η₀⁻ᵏᵗ</em>, where <em>η₀</em><strong><em> </em></strong>and <em>k</em> are hyperparameters and t is the step number</li></ul> <p><strong>1/t Decay</strong></p> <ul><li><em>η = (η₀)/(1+kt), </em>where <em>η₀</em><strong><em> </em></strong>and <em>k</em> are hyperparameters and t is the step number.</li></ul> <h4>Tips for Momentum</h4> <p>The following schedule was suggested by Sutskever <em>et al.</em>, 2013</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/467/1*0LV_yZM5e516h1YFHaFXDA.png"/></figure> <p>where, <em>γ_max</em> was chosen from {0.999, 0.995, 0.99, 0.9, 0}.</p> <h3>Line Search</h3> <p>In practice, often a line search is done to find a relatively better value of <em>η</em>. In line search, we update <em>w</em> using different learning rates (<em>η</em>) and check the updated model’s error in every iteration. Ultimately, we retain that updated value of <em>w</em> which gives the lowest loss. Take a look at the code:</p> <p>Essentially at each step, we are trying to use the best <em>η</em> value from the available choices. This is obviously not the best idea. We are doing many more computations in each step but that’s the trade-off for finding the best learning rate. Today, there are cooler ways to do this.</p> <h4>Line Search in Action</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/468/1*8lDYTCFKGAUHcsJpbzdGsQ.gif"/></figure> <p>Clearly, convergence is faster than vanilla gradient descent (see <a href="https://towardsdatascience.com/learning-parameters-part-1-eb3e8bb9ffbb?source=your_stories_page---------------------------">part 1</a>). We see some oscillations but notice that these oscillations are quite different from what we see in momentum and NAG (see <a href="https://towardsdatascience.com/learning-parameters-part-2-a190bef2d12">part 2</a>).</p> <p><strong>Note:</strong> Leslie N. Smith in his 2015 paper, <a href="https://arxiv.org/pdf/1506.01186.pdf"><em>Cyclical Learning Rates for Training Neural Networks</em></a><em> </em>proposed a smarter way than line search. I refer the reader to <a href="https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0">this medium post</a> by <a href="https://towardsdatascience.com/@surmenok">Pavel Surmenok</a> to read more about it.</p> <h3>Conclusion</h3> <p>In this part of the learning parameters series, we looked at some heuristic that can help us tune the learning rate and momentum for better training. We also looked at Line Search, a once-popular method to finding the best learning rate at every step of the gradient update. In the next (final) part of the learning parameters series, we will closely look at gradient descent with adaptive learning rate, specifically the following optimizers — AdaGrad, RMSProp, and Adam.</p> <p>You can find the next part here:</p> <ul><li><a href="https://towardsdatascience.com/learning-parameters-part-5-65a2f3583f7d">Learning Parameters, Part 5: AdaGrad, RMSProp, and Adam</a></li></ul> <h3>Acknowledgment</h3> <p>A lot of credit goes to <a href="https://www.cse.iitm.ac.in/~miteshk/"><strong>Prof. Mitesh M Khapra</strong></a> and the TAs of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html"><strong>CS7015: Deep Learning</strong></a><strong> </strong>course by IIT Madras for such rich content and creative visualizations. I merely just compiled the provided lecture notes and lecture videos concisely.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*fRGHjjqjl5P6IArtZpx_Hg.jpeg"/></figure> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6a18d1d3000b" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/towards-data-science/learning-parameters-part-4-6a18d1d3000b">Learning Parameters Part 4: Tips For Adjusting Learning Rate, Line Search</a> was originally published in <a href="https://medium.com/towards-data-science">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Learning Parameters, Part 3: Stochastic &amp;amp; Mini-Batch Gradient Descent</title><link href="https://akshaychandra.com/blog/2019/learning-parameters-part-3-stochastic-mini-batch-gradient-descent/" rel="alternate" type="text/html" title="Learning Parameters, Part 3: Stochastic &amp;amp; Mini-Batch Gradient Descent"/><published>2019-05-16T12:50:50+00:00</published><updated>2019-05-16T12:50:50+00:00</updated><id>https://akshaychandra.com/blog/2019/learning-parameters-part-3-stochastic--mini-batch-gradient-descent</id><content type="html" xml:base="https://akshaychandra.com/blog/2019/learning-parameters-part-3-stochastic-mini-batch-gradient-descent/"><![CDATA[<h4><a href="https://medium.com/tag/learning-parameters/latest">Learning Parameters</a></h4> <h4>Let’s digress a bit from optimizers and talk about the stochastic<br/>versions of these algorithms.</h4> <p>In part 2, we looked at two useful variants of gradient descent — <a href="https://towardsdatascience.com/learning-parameters-part-2-a190bef2d12">Momentum-Based and Nesterov Accelerated Gradient Descent</a>. In this post, we are going to look at stochastic versions of gradient descent. You can check out all the posts in the <strong><em>Learning Parameters </em></strong>series by clicking on the kicker tag at the top of this post.</p> <blockquote>Citation Note: Most of the content and figures in this blog are directly taken from Lecture 5 of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html">CS7015: Deep Learning</a> course offered by <a href="https://www.cse.iitm.ac.in/~miteshk/">Prof. Mitesh Khapra</a> at IIT-Madras.</blockquote> <h3>Motivation</h3> <p>Let us look at vanilla gradient descent we talked about in part-1 of the series.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/6f6b3d0514e51110ee07f8afc381d719/href">https://medium.com/media/6f6b3d0514e51110ee07f8afc381d719/href</a></iframe> <p>If you observe the block of code between the two weirdly commented lines, you notice that the gradient is calculated across the entire dataset. Meaning, the algorithm goes over the entire data once before updating the parameters. Why? Because this is the true gradient of the loss as derived earlier in part-1 (the sum of the gradients of the losses corresponding to each data point). This is a good thing as we are not approximating anything. Hence, all theoretical assumptions and guarantees hold (in other words each step guarantees that the loss will decrease). Is this desirable? Sure it is, but what is the flipside?</p> <p>Imagine we have a million points in the training data. To make 1 update to <strong><em>w</em></strong>, <strong><em>b</em></strong> the algorithm makes a million calculations. Obviously, this could be very slow!! Can we do something better? Yes, let’s look at stochastic gradient descent.</p> <h3>Stochastic Gradient Descent</h3> <p>Stochastic gradient descent<strong> </strong>(often shortened to SGD) is an iterative method for optimizing a differentiable objective function, a stochastic approximation of gradient descent optimization. Basically, you are going with an approximation of some sort instead of the noble ‘true gradient’. Stochastic gradient descent is the dominant method used to train deep learning models. Let’s straightaway look at the code for SGD.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/3aca6b1e6362712f57c10ecb8e8f6049/href">https://medium.com/media/3aca6b1e6362712f57c10ecb8e8f6049/href</a></iframe> <p>Here’s what’s going on — instead of making an update by calculating gradients for all the data points, we make an update with gradients of just one data point at a time. Thus, the name stochastic, as we are estimating the total gradient based on a single data point. Almost like tossing a coin only once and estimating P(heads). Now if we have a million data points we will make a million updates in each epoch (1 epoch = 1 pass over the data; 1 step = 1 update). What is the flipside? It is an approximate (rather stochastic) gradient so no guarantee that each step will decrease the loss.</p> <h4>SGD In Action</h4> <p>Let us see this algorithm geometrically when we have a few data points.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/510/1*EM62UF9uHIxgNmJQETYgZw.gif"/></figure> <p>If you look closely, you can see that our descent makes many tiny oscillations. Why? Because we are making greedy decisions. Each point is trying to push the parameters in a direction most favorable to it (without being aware of how this affects other points). A parameter update which is locally favorable to one point may harm other points (its almost as if the data points are competing with each other). Can we reduce the oscillations by improving our stochastic estimates of the gradient (currently estimated from just 1 data point at a time)? Yes, let’s look at mini-batch gradient descent.</p> <h3>Mini-Batch Gradient Descent</h3> <p>In the case of mini-batch, instead of making an update with gradients of one data point at a time, we calculate gradients of a batch of data points, of size, say k. Let’s look at the code of MBGD.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/8c1bfc16dda6de8e308403a00a3d5a97/href">https://medium.com/media/8c1bfc16dda6de8e308403a00a3d5a97/href</a></iframe> <p>Notice that the algorithm updates the parameters after it sees a <em>mini_batch_size</em> number of data points. The stochastic estimates should now be slightly better.</p> <h4>Mini-Batch In Action</h4> <p>Let’s see this algorithm in action when we have <em>k</em>/<em>mini_batch_size</em> = 2.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/470/1*jGzsLBN07fS4ns4kFZmrvQ.gif"/></figure> <p>Even with a batch size of <em>k=2,</em> the oscillations have reduced slightly. Why? Because we now have somewhat better estimates of the gradient (analogy: we are now tossing the coin <em>k=2</em> times to estimate P(heads)). The higher the value of k, the more accurate the estimates will be. In practice, typical values of k are 16, 32, 64. Of course, there are still oscillations, and they will always be there as long as we are using an approximate gradient as opposed<br/>to the ‘true gradient.’</p> <p>The illustration isn’t clear, and on top of that the <em>k</em> is just 2, so it is hard to see much of a difference. But trust the math, mini-batch helps us get slightly better gradient estimates.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*eoh2R7LXQ2UmRUYdeGxsEA.png"/></figure> <h3>SGD With Momentum And NAG</h3> <p>We can have stochastic versions of momentum based gradient descent and Nesterov accelerated gradient descent.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/801/1*30tXOexQixKbDPkRjJicNA.png"/></figure> <p>While the stochastic versions of both Momentum (red)and NAG (blue) exhibit oscillations the relative advantage of NAG over Momentum still holds (i.e., NAG takes relatively shorter u-turns). Furthermore, both of them are faster than stochastic gradient descent (after 60 steps, stochastic gradient descent [black - left figure] still exhibits a very high error whereas NAG and momentum are close to convergence).</p> <p>And, of course, we can also have the mini-batch versions of Momentum and NAG but just not in this post.</p> <h3>Conclusion</h3> <p>In this part of the learning parameters series, we looked at variations of the gradient descent algorithm that approximate the gradients updates — Stochastic Gradient Descent and Mini-Batch Gradient Descent. We looked at the key differences between them, python code implementations of both the methods and also illustrated their convergence graphically on a toy problem. We also visualized stochastic versions of Momentum and NAG. In the next post, we will discuss a few useful tips for adjusting the learning rate and momentum related parameters and briefly look at what line search is.</p> <p>Read all about it in the next post of this series at:</p> <ul><li><a href="https://towardsdatascience.com/learning-parameters-part-4-6a18d1d3000b">Learning Parameters, Part 4: Tips For Adjusting Learning Rate &amp; Momentum, Line Search</a></li></ul> <h3>Acknowledgment</h3> <p>A lot of credit goes to <a href="https://www.cse.iitm.ac.in/~miteshk/"><strong>Prof. Mitesh M Khapra</strong></a> and the TAs of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html"><strong>CS7015: Deep Learning</strong></a><strong> </strong>course by IIT Madras for such rich content and creative visualizations. I merely just compiled the provided lecture notes and lecture videos concisely.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/471/1*gRfVnXstuPNmQX_326P9QQ.png"/></figure> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ee8558f65dd7" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/towards-data-science/learning-parameters-part-3-ee8558f65dd7">Learning Parameters, Part 3: Stochastic &amp; Mini-Batch Gradient Descent</a> was originally published in <a href="https://medium.com/towards-data-science">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Learning Parameters, Part 2: Momentum-Based And Nesterov Accelerated Gradient Descent</title><link href="https://akshaychandra.com/blog/2019/learning-parameters-part-2-momentum-based-and-nesterov-accelerated-gradient-descent/" rel="alternate" type="text/html" title="Learning Parameters, Part 2: Momentum-Based And Nesterov Accelerated Gradient Descent"/><published>2019-05-15T12:44:13+00:00</published><updated>2019-05-15T12:44:13+00:00</updated><id>https://akshaychandra.com/blog/2019/learning-parameters-part-2-momentum-based-and-nesterov-accelerated-gradient-descent</id><content type="html" xml:base="https://akshaychandra.com/blog/2019/learning-parameters-part-2-momentum-based-and-nesterov-accelerated-gradient-descent/"><![CDATA[<h4><a href="https://medium.com/tag/learning-parameters/latest">Learning Parameters</a></h4> <h3>Learning Parameters, Part 2: Momentum-Based &amp; Nesterov Accelerated Gradient Descent</h3> <h4>Let’s look at two simple, yet very useful variants of gradient descent.</h4> <p>In this post, we look at how the gentle-surface limitation of Gradient Descent can be overcome using the concept of momentum to some extent. Make sure you check out my blog post — <a href="https://towardsdatascience.com/learning-parameters-part-1-eb3e8bb9ffbb">Learning Parameters, Part-1: Gradient Descent</a>, if you are unclear of what this is about. Throughout the blog post, we work with the same toy problem introduced in part-1. You can check out all the posts in the <strong><em>Learning Parameters </em></strong>series by clicking on the kicker tag at the top of this post.</p> <p>In part-1, we saw a clear illustration of a curve where the gradient can be small in gentle regions of the error surface, and this could slow things down. Let’s look at what momentum has to offer overcome this drawback.</p> <blockquote>Citation Note: Most of the content and figures in this blog are directly taken from Lecture 5 of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html">CS7015: Deep Learning</a> course offered by <a href="https://www.cse.iitm.ac.in/~miteshk/">Prof. Mitesh Khapra</a> at IIT-Madras.</blockquote> <h3>Momentum-Based Gradient Descent</h3> <p>The intuition behind MBGD from the mountaineer’s perspective (yes the same trite metaphor we used in part-1) is</p> <blockquote>If I am repeatedly being asked to move in the same direction then I should probably gain some confidence and start taking bigger steps in that direction. Just as a ball gains momentum while rolling down a slope.</blockquote> <h4>The Momentum Update Rule</h4> <p>We accommodate the momentum concept in the gradient update rule as follows:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/461/1*NosPqDgX13dZbvs8E-a7FA.png"/></figure> <p>In addition to the current update, we also look at the history of updates. I encourage you to take your time to process the new update rule and try and put it on paper how the <em>update </em>term changes in every step. Or keep reading. Breaking it down we get</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/908/1*ZDBsBanwX5jSFse4m2fxMQ.png"/></figure> <p>You can see that the current update is proportional to not just the present gradient but also gradients of previous steps, although their contribution reduces every time step by <strong><em>γ</em></strong>(gamma)<em> </em>times. And that is how we boost the magnitude of the update at gentle regions.</p> <h3>Momentum In Action</h3> <p>We modify the vanilla gradient descent code (shown in Part-1 &amp; also available <a href="https://gist.github.com/akshaychandra21/703ecc8949a01f472d17db3359d56985">here</a>) a little bit as follows:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9a502eeae55cdd5efa99837817179ab6/href">https://medium.com/media/9a502eeae55cdd5efa99837817179ab6/href</a></iframe> <p>From now on, we will only work with contour maps. Visualizing things in 3-D can be cumbersome, so contour maps come in as a handy alternative for representing functions with 2-D input and 1-D output. If you are unaware of/uncomfortable with them, please go through <strong>section 5</strong> of my basic stuff blog post — <a href="http://asasasasas"><em>Learning Parameters, Part-0: Basic Stuff</em></a> (there is even a self-test you can take to get better at interpreting them). Let’s see how effective MBGD is using the same toy neural network we introduced in part-1.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/494/1*sbUtb2ySE2DUSBYHhQJRaw.gif"/><figcaption>Momentum-Based Gradient Descent. 100 iterations of vanilla gradient descent make the black patch.</figcaption></figure> <p>It works. 100 iterations of vanilla gradient descent make the black patch, and it is evident that even in the regions having gentle slopes, momentum-based gradient descent can take substantial steps because the momentum carries it along.</p> <p>On a critical note, is moving fast always good? Would there be a situation where momentum would cause us to overshoot and run past our goal? Let test the MBGD by changing our input data so that we end up with a different error surface.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/428/1*sVpzlIuRspAhsS7Pnv0pWA.png"/></figure> <p>Say this one shown above, where the error is high on either side of the minima valley. Could momentum still work well in such cases or could it be detrimental instead? Let’s find out.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/496/1*t-kykynrtQ0olmFeNgIB0w.gif"/><figcaption>100 iterations of vanilla gradient descent make the black patch.</figcaption></figure> <p>We can observe that momentum-based gradient descent oscillates in and out of the minima valley as the momentum carries it out of the valley. This makes us take a lot of U-turns before finally converging. Despite these U-turns, it still converges faster than vanilla gradient descent. After 100 iterations momentum-based method has reached an error of 0.00001 whereas vanilla gradient descent is still stuck at an error of 0.36.</p> <p>Can we do something to reduce the oscillations/U-turns? Yes, Nesterov Accelerated Gradient Descent helps us do just that.</p> <h3>Nesterov Accelerated Gradient Descent</h3> <p>The intuition behind NAG can be put into a single phrase:</p> <blockquote>Look ahead before you leap!</blockquote> <figure><img alt="" src="https://cdn-images-1.medium.com/max/693/1*zjEZHrbahO4RSA7HHgsL6w.png"/></figure> <h4>The NAG Update Rule</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/508/1*ewQ9mtcJW00Dgp0ZJFNKmg.png"/></figure> <p>But why would looking ahead help us in avoiding overshoots? I urge you to pause and ponder. If it’s not clear, I am sure it will be clear in the next few minutes. Take a look at this figure for a moment.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6MEi74EMyPERHlAX-x2Slw.png"/><figcaption>A toy illustration.</figcaption></figure> <p>In figure (a), update 1 is positive i.e., the gradient is negative because as <strong><em>w_0</em></strong> increases <strong><em>L</em></strong> decreases. Even update 2 is positive as well and you can see that the update is slightly larger than update 1, thanks to momentum. By now, you should be convinced that update 3 will be bigger than both update 1 and 2 simply because of momentum and the positive update history. Update 4 is where things get interesting. In vanilla momentum case, due to the positive history, the update overshoots and the descent recovers by doing negative updates.</p> <p>But in NAG’s case, every update happens in two steps — first, a partial update, where we get to the <em>look_ahead</em> point and then the final update (see the NAG update rule), see figure (b). First 3 updates of NAG are pretty similar to the momentum-based method as both the updates (partial and final) are positive in those cases. But the real difference becomes apparent during update 4. As usual, each update happens in two stages, the partial update (4a) is positive, but the final update (4b) would be negative as the calculated gradient at <strong><em>w_lookahead </em></strong>would be negative (convince yourself by observing the graph). This negative final update slightly reduces the overall magnitude of the update, still resulting in an overshoot but a smaller one when compared to the vanilla momentum-based gradient descent. And that my friend, is how NAG helps us in reducing the overshoots, i.e. making us take shorter U-turns.</p> <h3>NAG In Action</h3> <p>By updating the momentum code slightly to do both the partial update and the full update, we get the code for NAG.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/4dbc0f1e6f9e762def97e1f2d0e43376/href">https://medium.com/media/4dbc0f1e6f9e762def97e1f2d0e43376/href</a></iframe> <p>Let’s compare the convergence of momentum-based method with NAG using the same toy example and the same error surface we used while illustrating the momentum-based method.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/496/1*_Q1plMUkXfLPTRCCTRg36g.gif"/><figcaption>You can see that (I hope you can) NAG (blue) is taking smaller U-turns compared to vanilla momentum (red).</figcaption></figure> <p>NAG is certainly making smaller oscillations/taking shorter U-turns even when approaching the minima valleys on the error surface. Looking ahead helps NAG in correcting its course quicker than momentum-based gradient descent. Hence the oscillations are smaller and the chances of escaping the minima valley also smaller. Earlier, we proved that looking back helps <em>*ahem momentum ahem*</em> and we now proved that looking ahead also helps.</p> <h3>Conclusion</h3> <p>In this blog post, we looked at two simple, yet hybrid versions of gradient descent that help us converge faster — <em>Momentum-Based Gradient Descent</em> and <em>Nesterov Accelerated Gradient Descent (NAG) </em>and also discussed why and where NAG beats vanilla momentum-based method. We looked at the nuances in their update rules, python code implementations of the methods and also illustrated their convergence graphically on a toy example. In the next post, we will digress a little bit and talk about stochastic versions of these algorithms.</p> <p>Read all about it in the next post of this series at:</p> <ul><li><a href="https://towardsdatascience.com/ee8558f65dd7">Learning Parameters, Part 3: Stochastic &amp; Mini-Batch Gradient Descent</a></li></ul> <h3>Acknowledgment</h3> <p>A lot of credit goes to <a href="https://www.cse.iitm.ac.in/~miteshk/"><strong>Prof. Mitesh M Khapra</strong></a> and the TAs of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html"><strong>CS7015: Deep Learning</strong></a><strong> </strong>course by IIT Madras for such rich content and creative visualizations. I merely just compiled the provided lecture notes and lecture videos concisely.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a190bef2d12" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/towards-data-science/learning-parameters-part-2-a190bef2d12">Learning Parameters, Part 2: Momentum-Based And Nesterov Accelerated Gradient Descent</a> was originally published in <a href="https://medium.com/towards-data-science">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Learning Parameters, Part 1: Gradient Descent</title><link href="https://akshaychandra.com/blog/2019/learning-parameters-part-1-gradient-descent/" rel="alternate" type="text/html" title="Learning Parameters, Part 1: Gradient Descent"/><published>2019-05-14T21:20:57+00:00</published><updated>2019-05-14T21:20:57+00:00</updated><id>https://akshaychandra.com/blog/2019/learning-parameters-part-1-gradient-descent</id><content type="html" xml:base="https://akshaychandra.com/blog/2019/learning-parameters-part-1-gradient-descent/"><![CDATA[<h4><a href="https://towardsdatascience.com/tagged/learning-parameters">Learning Parameters</a></h4> <h4>Gradient Descent is an iterative optimization algorithm for finding the (local) minimum of a function.</h4> <p>Gradient Descent is one of the most popular techniques in optimization, very commonly used in training neural networks. It is intuitive and explainable, given the right background of essential Calculus. Take a look at this blog post of mine — <a href="https://towardsdatascience.com/learning-parameters-part-0-5cfffd647bdc">Part 0</a> of sorts, that covers some of the prerequisites needed to make better sense of this series. You can check out all the posts in the <strong><em>Learning Parameters</em></strong> series by clicking on the kicker tagged at the top of this post.</p> <p>In this blog post, we build up the motivation for Gradient Descent using a toy neural network. We also derive Gradient Descent update rule from scratch and interpret what happens geometrically using the same toy neural network.</p> <blockquote>Citation Note: Most of the content and figures in this blog are directly taken from Lecture 5 of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html">CS7015: Deep Learning</a> course offered by <a href="https://www.cse.iitm.ac.in/~miteshk/">Prof. Mitesh Khapra</a> at IIT-Madras.</blockquote> <h3>A Trite Metaphor</h3> <p>Imagine you’re standing on a mountain, there could be a lot of possible paths available to you to descend. Gradient Descent (GD) in a nutshell gives you a principled way of descending the mountain.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/465/1*i3Gsdnr4srsBoLhPVoEUWQ.png"/></figure> <p>GD encourages you first to find a direction in which the mountain has the steepest ascent and asks you to go quite the opposite to that. You might argue that this seemingly simple idea, might not always work. You are right, GD could make you walk slow even when the surface is flat (when you can run), but we will address the limitations later at the end of the post.</p> <h3>Motivation</h3> <p>Taking the metaphor forward to a toy example, let’s say we want to train a toy neural network with just one neuron. And the premise is as follows:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/962/1*ZBDrFo0woUzqNPjP0TMs-Q.png"/></figure> <p>The training objective is to find the best combination of <strong><em>w</em></strong><em> and </em><strong><em>b </em></strong>that makes function<em> </em><strong><em>L(w, b)</em></strong><em> </em>output its<em> </em>minimum value<em>.</em></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/378/1*HaUe7o3HKmyS-JpdgS_iuQ.png"/></figure> <p>Now, what does it mean to train a network? Suppose we train the toy network with (<em>x, y</em>)<em> = </em>(0.5, 0.2)<em> </em>and (2.5, 0.9), at the end of the training, we expect to find <strong><em>w*</em></strong> and <strong><em>b*</em></strong> such that<em> f</em>(0.5) outputs 0.2 and <em>f</em>(2.5) outputs 0.9. We hope to see a sigmoid function such that (0.5, 0.2) and (2.5, 0.9) lie on the sigmoid.</p> <h4>Brute Force Stuff You Will Never Do</h4> <p>Can we try to find such a <strong><em>w*</em></strong>, <strong><em>b*</em></strong> manually? <br/>Let us try a random guess.. (say, w = 0.5, b = 0)</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*NkCdVlIPhoMnVhW-Ntu4Kw.png"/></figure> <p>Let’s keep guessing. Shall we?</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/929/1*bj0KLAu8bluOe1AxIu2VNA.png"/></figure> <h4>Geometric Interpretation Of Stuff You Will Never Do</h4> <p>Can we visualize the guesswork? We can! Since we have only 2 points and 2 parameters <strong><em>(w, b)</em></strong> we can easily plot <strong><em>L(w, b)</em></strong> for different values of <strong><em>(w, b)</em></strong> and pick the one where <strong><em>L(w, b)</em></strong> is minimum.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/449/1*rg7pGh5YSNlm2ghoum83wA.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/984/1*LPxbwM51k2iXDsM5vrqcpw.gif"/></figure> <p>But of course, this becomes intractable once you have many more data points and many more parameters! Further, here we have plotted the error surface only for a small range of <strong><em>(w, b), </em></strong>from (−6, 6) and not from (−inf, inf). Gradient Descent to the rescue!</p> <h3>Gradient Descent</h3> <p>If it’s not already clear, the task at hand is all about finding the best combination of parameters that minimize the loss function. Gradient Descent gives us a principled way of traversing the error surface so that we can reach the minimum value quickly without resorting to brute force search.</p> <h4>Deriving The Gradient Descent Rule</h4> <p>It is reasonable to randomly initialize <strong><em>w</em></strong> and <strong><em>b</em></strong> and then update them iteratively in the <strong>best way</strong> possible to reach our goal of minimizing the loss function. Let us mathematically define this.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/798/1*jKpqYCSvhEEv-jynCwNKdQ.png"/></figure> <p>But how do we find the most ‘desirable’ change in <em>θ</em>? What is the right <strong>Δ</strong><em>θ</em> to use? The answer comes from the <a href="http://fourier.eng.hmc.edu/e176/lectures/NM/node45.html"><strong>Taylor Series</strong></a>.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/964/1*9B5TFde4a7Yh0Yt35nsBeA.png"/></figure> <p>This means the direction <em>u </em>or<em> </em><strong>Δ</strong><em>θ </em>that we intend to move in should be at 180-degree angle w.r.t. the gradient. At a given point on the loss surface, we move in the direction opposite to the gradient of the loss function at that point. This is the golden Gradient Descent Rule!!</p> <h4>Weight/Parameter Update Rule</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*imRrzCELAOGiGHPg6YMlsg.png"/></figure> <h4>Algorithm</h4> <p>Now that we have a more principled way of moving in the <strong><em>w-b</em></strong><em> </em>plane than our brute force algorithm. Let’s create an algorithm from this rule…</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/479/1*Gnc1n67aNhaqaByWe-y5HA.png"/></figure> <h3>Gradient Descent In Action</h3> <p>To see GD in practice, we first have to derive ∇<strong><em>w</em></strong> and ∇<strong><em>b</em></strong> for our toy neural network. If you work it out, you’ll see that they are as follows:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/653/1*RjdP7GPIZjtsj3YQUn5oNA.png"/></figure> <h4>Python Code</h4> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/b9be719720e007b31764234a93cda0b4/href">https://medium.com/media/b9be719720e007b31764234a93cda0b4/href</a></iframe> <h4>Geometric Interpretation</h4> <p>Let’s start from a random point on the error surface and look at the updates.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/492/1*ghMZkEOArRtRVGOFMu4aOQ.gif"/></figure> <h3>Limitation</h3> <p>Gradient Descent in its raw form has an obvious drawback. Let look at an example curve <em>f(x) = x² + 1,</em> shown below:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/319/1*_V2aSf3uNzbWEy_JRYak-A.png"/></figure> <ul><li>When the curve is steep the gradient (∇y1/∇x1) is large.</li><li>When the curve is gentle (∇y2/∇x2) is small.</li></ul> <p>Recall that our weight updates are proportional to the gradient <strong><em>w = w — η∇w</em></strong><em>. </em>Hence, in the regions where the curve is gentle, the updates are small whereas in the regions where the curve is steep the updates are large. Let’s see what happens when we start from a different point on the surface.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/454/1*qJ4t5n_9-6AnpOufeYBmMA.gif"/></figure> <p>Irrespective of where we start from, once we hit a surface which has a gentle slope, the progress slows down. Due to this, training methods could take forever to converge.</p> <h3>Conclusion</h3> <p>In this blog post, we made an argument to emphasize on the need of Gradient Descent using a toy neural network. We also derived Gradient Descent update rule from scratch and interpreted what goes on with each update geometrically using the same toy neural network. We also addressed a significant limitation of GD, issue of slowing down at gentle regions, in its raw form with a curve illustration. <em>Momentum-Based Gradient Descent</em> overcomes this drawback to an extent by letting the ‘momentum’ of recent gradient updates control the update magnitude in the current step.</p> <p>Read all about it in the next post of this series at:</p> <ul><li><a href="https://towardsdatascience.com/learning-parameters-part-2-a190bef2d12">Learning Parameters, Part 2: Momentum-Based And Nesterov Accelerated Gradient Descent</a></li></ul> <h3>Acknowledgment</h3> <p>A lot of credit goes to <a href="https://www.cse.iitm.ac.in/~miteshk/"><strong>Prof. Mitesh M Khapra</strong></a> and the TAs of <a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html"><strong>CS7015: Deep Learning</strong></a><strong> </strong>course by IIT Madras for such rich content and creative visualizations. I merely just compiled the provided lecture notes and lecture videos concisely.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=eb3e8bb9ffbb" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/towards-data-science/learning-parameters-part-1-eb3e8bb9ffbb">Learning Parameters, Part 1: Gradient Descent</a> was originally published in <a href="https://medium.com/towards-data-science">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Learning Parameters, Part 0: Basic Stuff</title><link href="https://akshaychandra.com/blog/2019/learning-parameters-part-0-basic-stuff/" rel="alternate" type="text/html" title="Learning Parameters, Part 0: Basic Stuff"/><published>2019-05-14T21:20:41+00:00</published><updated>2019-05-14T21:20:41+00:00</updated><id>https://akshaychandra.com/blog/2019/learning-parameters-part-0-basic-stuff</id><content type="html" xml:base="https://akshaychandra.com/blog/2019/learning-parameters-part-0-basic-stuff/"><![CDATA[<h4>A quick look at some basic stuff essential to understand how parameters are learned.</h4> <p>This is an optional read for the 5 part series I wrote on learning parameters. In this post, you will find some basic stuff you’d need to understand my other blog posts on how deep neural networks learn their parameters better. You can check out all the posts in the <strong><em>Learning Parameters </em></strong>series by clicking on the kicker tag at the top of this post.</p> <p>We will briefly look at the following topics:</p> <ol><li>Multivariable Functions</li><li>Local Minimum vs. Global Minimum</li><li>Understanding The Gradient</li><li>Cost or Loss Function</li><li>Contour Maps</li></ol> <h3>1. Multivariable Functions</h3> <p>A multivariable function is just a function whose input and/or output is made up of multiple numbers/variables. E.g., <em>f(x, y) = z= x² + y².</em></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/482/1*4M10mQ0R-y9sFymnIPdvpw.gif"/><figcaption>Fig1. z = x² + y² graph by Google. <strong>Image Source:</strong> Google the equation.</figcaption></figure> <p>Functions with multiple outputs are also called multivariable functions, but they are irrelevant here.</p> <h3>3. Understanding The Gradient</h3> <p>The term “gradient” is just a fancy way of referring to derivatives of multivariable functions. While a derivative can be defined for functions of a single variable, for functions of several variables the gradient takes its place. The gradient is a vector-valued function while the derivative is scalar-valued.</p> <p>The derivative of a single variable function, denoted by <strong><em>f’(x)</em></strong><em> </em>or<em> </em><strong><em>df</em>/<em>dx</em></strong><em>, </em>tells us how much the function value changes with a unit change in the input. But if a function takes multiple inputs <strong><em>x</em></strong><em> </em>and <strong><em>y</em></strong>, we need to know how much the value of the function changes with respect to <strong><em>x</em> </strong>and <strong><em>y</em></strong> individually i.e., how much <strong><em>f(x,y)</em></strong> changes when <strong><em>x</em></strong> changes a teeny-tiny bit while keeping <strong><em>y</em></strong> constant and also how much it changes when <strong><em>y</em></strong> changes a teeny-tiny bit while keeping <strong><em>x</em></strong><em> </em>constant. These are called <em>partial derivatives </em>of the function often denoted by <strong>∂<em>f</em>/<em>∂x</em></strong><em> </em>and<em> </em><strong><em>∂f</em>/∂y </strong>respectively and when you put these two innocent scalars in a vector, denoted by ∇<strong><em>f</em></strong><em>,</em><strong><em> </em></strong>like the following, you get what we call the hero of calculus, the gradient!!</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/184/1*XJaTT0wevEDbtyYkKi-0Lg.png"/></figure> <h4>Properties Of The Gradient</h4> <p>There are many more properties but let us just focus on two necessary ones:</p> <ul><li>A gradient points in the direction of greatest increase of a function.</li><li>It is zero at a local maximum or local minimum (because there is no single direction of increase)</li></ul> <p>The first property says that if you imagine standing at a point <em>(x, y)</em> in the input space of <em>f</em>, the vector ∇<em>f</em>(<em>x</em>, <em>y)</em> tells you which direction you should travel to increase the value of <em>f</em> most rapidly. This obviously generalizes to N dims. When I first learned this in school, it was not at all obvious why this would be the case, but check out these <a href="https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives#partial-derivative-and-gradient-articles">set of videos</a> on Khan Academy to know more about this.</p> <p>To understand the second property, we need to know what a derivate is, visually. The derivate of a line is the slope of the line, the derivative of a curve at any point is the slope of the tangent to that curve at that point.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/229/1*ugvwTNWM34pDwvmiq3D4TQ.gif"/><figcaption><strong>y(x)=x²-3x+3</strong> with the tangent line through the point <strong>(3,3)</strong>. <strong>Image Source:</strong> [5]</figcaption></figure> <p>For functions of two variables (a surface), there are many lines tangent to the surface at a given point. If we have a nice enough function, all of these lines form a plane called the tangent plane to the surface at the point.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/315/1*Up-PuWmM_gGii1cdbpkwbQ.gif"/><figcaption>The tangent plane to the surface <strong><em>z=-x²-y²</em></strong> at the point <strong>(0,2)</strong>. <strong>Image Source:</strong> [5]</figcaption></figure> <p>I am sure you can convince yourself that this plane at the maximum of the surface, i.e., at the tip of the surface, will be parallel to the <strong><em>XY</em></strong>-plane Which suggests that the tangent’s slope is 0 at maximum. If you can’t, look at the following.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*OJIB1w0M7XfesTIWix8Xcw.png"/><figcaption>The tangent planes to the surfaces<strong> z=-x²-y²</strong> and <strong>z=x²+y²</strong> at their maximum and minimum respectively.</figcaption></figure> <h3>3. Cost/Loss Function</h3> <p>Arguably, the value you’d want to care about the most while training a neural network is the loss/cost. It measures how “good” or “bad” your model is fitting the data. Any GD like algorithm’s primary goal is to find the set of parameters that produce the least cost. All the drama around references like “finding the minimum,” “walking on the error surface” are just talking about adjusting the parameters in a way we end up with the least possible cost function value. You could think of a cost function as a multivariable function with model weights as the parameters. Try not to think beyond 2 parameters — you know why!</p> <p>There are many ways you can frame your loss function. Different types of problems (classification &amp; regression) can have different types of loss functions framed that best represent the performance of the models, which is for another day, another post. For now, this intuition is good enough to understand the rest of the story. You can watch this video [6] by Siraj Raval to know more about loss functions.</p> <h3>4. Local Minimum vs. Global Minimum</h3> <p>In figure 1, how many “minimums” do you see? I see just one. How nice! If your loss function looked like that, you could start your descent from anywhere on the graph (I mean, keep changing your parameters) with a reliable guide alongside (ahem Gradient Descent ahem), there is a good chance you’d end up at that sweet dark green spot on the surface. Too bad, the error surfaces you’d end up while optimizing even the smallest networks could be bumpier and in some sense, scarier.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/351/1*XrL0tp9rHSeN5SosuAvC_g.png"/><figcaption>Fig2. Not so friendly cost function eh? <strong>Image Source: </strong>[1]</figcaption></figure> <p>In many real-world cases, the minimum values you are going attain depend significantly on the point at which you start the descent. If you started your descent near a valley, the GD algorithm would most definitely force you to go into that valley (a local minimum), but the real minimum (global minimum) could be somewhere else on the surface.</p> <p>Take a look at the cost function of the two of the most popular neural networks, VGG-56 and VGG-110.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/882/1*YOkeatQyMDHEK9KLV4Rmgw.png"/><figcaption>Fig3. “Bumpier” and “scarier” cost functions of VGG-56 and VGG-110 networks. <strong>Image Source:</strong> [3]</figcaption></figure> <blockquote>Pause and ponder!! <br/>How can you possibly visualise a “big” network’s cost function in 3D? Big networks often have millions of parameters so how is this even possible? Read the paper linked in the references to find out.</blockquote> <h3>5. Contours</h3> <p>Visualizing things in 3-D can sometimes be a bit cumbersome, and contour maps come in as a handy alternative for representing functions with 2-D input and 1-D output. It is easier to explain it graphically than in text.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*x729LmFP5y9fI6aePt249Q.png"/><figcaption>Fig4. Step Wise Illustration Of Contour Mapping Process. <strong>Images Taken From </strong>[7]</figcaption></figure> <h4>The Contour Mapping Process</h4> <p><strong>Step 1: </strong>Start with the graph of the function.<br/><strong>Step 2: </strong>Slice it up in regular intervals with planes parallel to the input plane at different heights.<br/><strong>Step 3: </strong>Mark all the places on the graph the plane cuts through. <br/><strong>Step 4: </strong>Project the markings on a 2-D plane, label the corresponding plane heights and map them accordingly.</p> <h4>Key Takeaways</h4> <ul><li>A small distance between the contours indicates a steep slope along that direction</li><li>A large distance between the contours indicates a gentle slope along that direction</li></ul> <figure><img alt="" src="https://cdn-images-1.medium.com/max/262/1*bsgrLfNTzZ7LUCA0T89onA.png"/><figcaption>Fig5.<strong> Image Source:</strong> Wikipedia</figcaption></figure> <h4>Test Your Understanding</h4> <p>It is alright if you are still unable to comprehend the concept of contour maps completely. You can test your understanding by guessing the 3-D plots (without looking at the solution present on the right column of Figure 6) for the following contour maps.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*k65Tvna-KznaCgyu6LOCIg.png"/><figcaption>Fig6. Test Your Understanding! <strong>Image Source: </strong>[8]</figcaption></figure> <p>Please read this brilliant article [7] by Khan Academy to know more about Contour Maps.</p> <p>Check out the next post in this series at :</p> <ul><li><a href="https://towardsdatascience.com/learning-parameters-part-1-eb3e8bb9ffbb">Learning Parameters, Part-1: Gradient Descent.</a></li></ul> <h3>References</h3> <ol><li><a href="https://math.oregonstate.edu/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/tangent/tangent.html">The hard thing about deep learning</a>, <a href="https://www.oreilly.com/people/4a99a-reza-zadeh">Reza Zadeh</a>.</li><li><a href="https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/">Intro to optimization in deep learning: Gradient Descent</a>, <a href="https://blog.paperspace.com/author/ayoosh/">Ayoosh Kathuria</a>.</li><li><a href="https://www.cs.umd.edu/~tomg/projects/landscapes/">Visualizing the Loss Landscape of Neural Nets</a>, CS-UMD.</li><li><a href="http://ruder.io/optimizing-gradient-descent/index.html">An overview of gradient descent optimization algorithms</a>, <a href="http://ruder.io/">Sebastian Ruder</a>.</li><li><a href="https://math.oregonstate.edu/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/tangent/tangent.html">Tangent Planes And Total Differentials</a>, Oregon State University.</li><li><a href="https://www.youtube.com/watch?v=IVVVjBSk9N0">Loss Functions Explained</a>, Siraj Raval.</li><li><a href="https://www.khanacademy.org/math/multivariable-calculus/thinking-about-multivariable-function/ways-to-represent-multivariable-functions/a/contour-maps">Contour Maps (article)</a>, Khan Academy.</li><li><a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html">CS7015: Deep Learning, Indian Institute Of Technology</a>, Madras.</li></ol> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5cfffd647bdc" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/towards-data-science/learning-parameters-part-0-5cfffd647bdc">Learning Parameters, Part 0: Basic Stuff</a> was originally published in <a href="https://medium.com/towards-data-science">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Mouse Cursor Control Using Facial Movements — An HCI Application</title><link href="https://akshaychandra.com/blog/2018/mouse-cursor-control-using-facial-movementsan-hci-application/" rel="alternate" type="text/html" title="Mouse Cursor Control Using Facial Movements — An HCI Application"/><published>2018-10-07T20:36:17+00:00</published><updated>2018-10-07T20:36:17+00:00</updated><id>https://akshaychandra.com/blog/2018/mouse-cursor-control-using-facial-movementsan-hci-application</id><content type="html" xml:base="https://akshaychandra.com/blog/2018/mouse-cursor-control-using-facial-movementsan-hci-application/"><![CDATA[<h3>Mouse Cursor Control Using Facial Movements — An HCI Application</h3> <p>This HCI (Human-Computer Interaction) application in Python(3.6) will allow you to control your mouse cursor with your facial movements, works with just your regular webcam. Its hands-free, no wearable hardware or sensors needed.</p> <p>Special thanks to <strong>Adrian Rosebrock</strong> for his amazing blog posts [2] [3], code snippets and his <a href="https://github.com/jrosebr1/imutils">imutils</a> library [7] that played an important role in making this idea of mine a reality.</p> <h3>Working Example</h3> <iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FL2XUKeLD6N8%3Ffeature%3Doembed&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DL2XUKeLD6N8&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FL2XUKeLD6N8%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube" width="854" height="480" frameborder="0" scrolling="no"><a href="https://medium.com/media/e2b36aa0f951ed26358c51a43691a8a4/href">https://medium.com/media/e2b36aa0f951ed26358c51a43691a8a4/href</a></iframe> <h3>Usage</h3> <p>Now, I definitely understand that these facial movements could be a little bit weird to do, especially when you are around people. Being a patient of <a href="https://www.healthline.com/health/benign-positional-vertigo">benign-positional-vertigo</a>, I hate doing some of these actions myself. But I hope to make them easier and less weird over time. Feel free to suggest some public friendly actions that I can incorporate in the project.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*OqOtL0Sffvqk86jG5sGAFw.jpeg"/></figure> <h3>Code</h3> <p>You can find the code files here:</p> <p><a href="https://github.com/acl21/Mouse_Cursor_Control_Handsfree">acl21/Mouse_Cursor_Control_Handsfree</a></p> <h4>Libraries Used</h4> <ul><li>Numpy — 1.13.3</li><li>OpenCV — 3.2.0</li><li>PyAutoGUI — 0.9.36</li><li>Dlib — 19.4.0</li><li>Imutils — 0.4.6</li></ul> <p>Execution steps are mentioned in the README.md of the repo. Feel free to raise an issue in case of any errors.</p> <h3>How It Works</h3> <p>This project is deeply centered around predicting the facial landmarks of a given face. We can accomplish a lot of things using these landmarks. From detecting eye-blinks [3] in a video to predicting emotions of the subject. The applications, outcomes, and possibilities of facial landmarks are immense and intriguing.</p> <p><a href="http://dlib.net/">Dlib</a>’s prebuilt model, which is essentially an implementation of [4], not only does a fast face-detection but also allows us to accurately predict 68 2D facial landmarks. Very handy.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EZ9o_UGKR6Z-F_Ea2jmyGg.jpeg"/></figure> <p>Using these predicted landmarks of the face, we can build appropriate features that will further allow us to detect certain actions, like using the eye-aspect-ratio (more on this below) to detect a blink or a wink, using the mouth-aspect-ratio to detect a yawn etc or maybe even a pout. In this project, these actions are programmed as triggers to control the mouse cursor. <a href="http://pyautogui.readthedocs.io">PyAutoGUI</a> library was used to move the cursor around.</p> <h4>Eye-Aspect-Ratio (EAR)</h4> <p>You will see that Eye-Aspect-Ratio [1] is the simplest and the most elegant feature that takes good advantage of the facial landmarks. EAR helps us in detecting blinks [3] and winks etc.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/772/1*6Ix1R90EmXixWYd5MGSJdQ.png"/></figure> <p>You can see that the EAR value drops whenever the eye closes. We can train a simple classifier to detect the drop. However, a normal <em>if</em> condition works just fine. Something like this:</p> <pre>if EAR &lt;= SOME_THRESHOLD:<br />      EYE_STATUS = &#39;CLOSE&#39;</pre> <h4>Mouth-Aspect-Ratio (MAR)</h4> <p>Highly inspired by the EAR feature, I tweaked the formula a little bit to get a metric that can detect opened/closed mouth. Unoriginal but it works.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/754/1*LC6YYNhB3aIzMTMVMY5Pdg.jpeg"/></figure> <p>Similar to EAR, MAR value goes up when the mouth opens. Similar intuitions hold true for this metric as well.</p> <h3>Prebuilt Model Details</h3> <p>The model offers two important functions. A detector to detect the face and a predictor to predict the landmarks. The face detector used is made using the classic Histogram of Oriented Gradients (HOG) feature combined with a linear classifier, an image pyramid, and sliding window detection scheme.</p> <p>The facial landmarks estimator was created by using Dlib’s implementation of the paper: <a href="https://www.semanticscholar.org/paper/One-millisecond-face-alignment-with-an-ensemble-of-Kazemi-Sullivan/1824b1ccace464ba275ccc86619feaa89018c0ad"><em>One Millisecond Face Alignment with an Ensemble of Regression Trees by Vahid Kazemi and Josephine Sullivan</em></a>, CVPR 2014. And was trained on the iBUG 300-W face landmark dataset: C. Sagonas, E. Antonakos, G, Tzimiropoulos, S. Zafeiriou, M. Pantic. 300 faces In-the-wild challenge: Database and results. <a href="https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/"><em>Image and Vision Computing (IMAVIS), Special Issue on Facial Landmark Localisation “In-The-Wild”. 2016</em></a>.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/872/1*rmy_Dtu2Dd5h5QbvbKbpag.png"/></figure> <p>You can get the trained model file from <a href="http://dlib.net/files,">http://dlib.net/files,</a> click on <strong>shape_predictor_68_face_landmarks.dat.bz2</strong>. The model, .dat file has to be in the project folder.</p> <p><strong>Note:</strong> The license for the iBUG 300-W dataset excludes commercial use. So you should contact Imperial College London to find out if it’s OK for you to use this model file in a commercial product.</p> <h3>References</h3> <p><strong>[1]</strong>. Tereza Soukupova´ and Jan Cˇ ech. <a href="https://vision.fe.uni-lj.si/cvww2016/proceedings/papers/05.pdf"><em>Real-Time Eye Blink Detection using Facial Landmarks</em></a>. In 21st Computer Vision Winter Workshop, February 2016.<br/><strong>[2]</strong>. Adrian Rosebrock. <a href="https://www.pyimagesearch.com/2017/04/10/detect-eyes-nose-lips-jaw-dlib-opencv-python/"><em>Detect eyes, nose, lips, and jaw with dlib, OpenCV, and Python</em></a>. <br/><strong>[3]</strong>. Adrian Rosebrock. <a href="https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/"><em>Eye blink detection with OpenCV, Python, and dlib</em></a>.<br/><strong>[4]</strong>. Vahid Kazemi, Josephine Sullivan. <a href="https://ieeexplore.ieee.org/document/6909637"><em>One millisecond face alignment with an ensemble of regression trees</em></a>. In CVPR, 2014.<br/><strong>[5]</strong>. S. Zafeiriou, G. Tzimiropoulos, and M. Pantic. <a href="http://ibug.doc.ic.ac.uk/resources/300-VW/.3"><em>The 300 videos in the wild (300-VW) facial landmark tracking in-the-wild challenge</em></a>. In ICCV Workshop, 2015. <br/><strong>[6]</strong>. C. Sagonas, G. Tzimiropoulos, S. Zafeiriou, M. Pantic. <a href="https://ibug.doc.ic.ac.uk/media/uploads/documents/sagonas_iccv_2013_300_w.pdf"><em>300 Faces in-the-Wild Challenge: The first facial landmark localization Challenge</em></a>. Proceedings of IEEE Int’l Conf. on Computer Vision (ICCV-W), 300 Faces in-the-Wild Challenge (300-W). Sydney, Australia, December 2013<br/><strong>[7]</strong>. Adrian Rosebrock. <em>Imutils</em>. <a href="https://github.com/jrosebr1/imutils">https://github.com/jrosebr1/imutils</a>.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GENBf59JzMt8oSNmH75mEA.jpeg"/><figcaption>Photo by <a href="https://unsplash.com/photos/28XgB4jULqg?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Orysya Dibrova</a> on <a href="https://unsplash.com/search/photos/computer-mouse-handsfree?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c16b0494a971" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/towards-data-science/mouse-control-facial-movements-hci-app-c16b0494a971">Mouse Cursor Control Using Facial Movements — An HCI Application</a> was originally published in <a href="https://medium.com/towards-data-science">TDS Archive</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry></feed>